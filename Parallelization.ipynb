{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization of IDA*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 4 engines with <class 'ipyparallel.cluster.launcher.MPIEngineSetLauncher'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Cluster(cluster_id='1648805262-8b7d', profile='default', controller=<running>, engine_sets=['1648805264'])>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "cluster = ipp.Cluster(engines='mpi', n=4)\n",
    "cluster.start_cluster_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.19s/engine]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DirectView [0, 1, 2, 3]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc = cluster.connect_client_sync()\n",
    "rc.wait_for_engines(4)\n",
    "dview = rc[:]\n",
    "dview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import mpi4py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def string2duration(string):\n",
    "    ''' \"01:50:19.3177493\" to duration in seconds'''\n",
    "    date =  datetime.strptime(string.split('.')[0], \"%H:%M:%S\")\n",
    "    return date.second + 60*date.minute + 3600*date.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def read_data(path):\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    nodes = data['nodes']\n",
    "    tasks = dict()\n",
    "    for task_str, info in nodes.items():\n",
    "        task = int(task_str)\n",
    "        tasks[task] = {'Data' : string2duration(info['Data']), 'Dependencies' : info['Dependencies']}\n",
    "    task_count = len(tasks)\n",
    "    print(\"Data loaded successfully. Number of tasks: \" + str(task_count))\n",
    "    return tasks, task_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dependencies(tasks):\n",
    "    #Tasks to child tasks / Tasks to parents / Task is terminal / Task is inital\n",
    "    task2childs = {task : list() for task in tasks}\n",
    "    task2parents = {task : list() for task in tasks}\n",
    "    for task, info in tasks.items():\n",
    "        #Add childs\n",
    "        list_task_parents = info['Dependencies']\n",
    "        for task_parent in list_task_parents:\n",
    "            task2childs[task_parent].append(task)\n",
    "        #Add parents\n",
    "        task2parents[task] = tasks[task]['Dependencies']\n",
    "    \n",
    "    return task2childs, task2parents\n",
    "    \n",
    "def task_is_terminal(task, task2childs):\n",
    "    return len(task2childs[task]) == 0\n",
    "def task_is_inital(task, task2parents):\n",
    "    return len(task2parents[task]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_static_bottom_level(task, tasks, task2childs, task2sbl):\n",
    "    task_duration = tasks[task][\"Data\"]\n",
    "    if task_is_terminal(task, task2childs):\n",
    "        sbl = task_duration\n",
    "    else:\n",
    "        list_sbl_child = list()\n",
    "        for task_child in task2childs[task]:\n",
    "            if task_child in task2sbl:\n",
    "                sbl_child = task2sbl[task_child]\n",
    "            else:\n",
    "                sbl_child = save_static_bottom_level(task_child, tasks, task2childs, task2sbl)\n",
    "            list_sbl_child.append(sbl_child)\n",
    "        sbl = max(list_sbl_child) + task_duration\n",
    "                \n",
    "    task2sbl[task] = sbl\n",
    "    return sbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbl(tasks, task2childs, task2parents):\n",
    "    task2sbl = {}\n",
    "    for task in tasks:\n",
    "        if task_is_inital(task, task2parents):\n",
    "            save_static_bottom_level(task, tasks, task2childs, task2sbl)\n",
    "    return task2sbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2letter(n):\n",
    "    '''0 to 'a', 1 to 'b', ... '''\n",
    "    return str(n)\n",
    "    \n",
    "def string2duration(string):\n",
    "    ''' \"01:50:19.3177493\" to duration in seconds'''\n",
    "    date =  datetime.strptime(string.split('.')[0], \"%H:%M:%S\")\n",
    "    return date.second + 60*date.minute + 3600*date.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "class Node():\n",
    "    def __init__(self, n_cores, parent = None, task_to_add = None, core_where_to_add = None, time_task_start = None, task_end_time = None):\n",
    "        '''Create a Node object ie a partial scheduling\n",
    "        parent = parent Node, None if root\n",
    "        task_to_add : task added to the partial schedule\n",
    "        core_where_to_add : core where to do task\n",
    "        time_task_start : instant where the core will start computing the task\n",
    "        '''   \n",
    "\n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.tasks_done_time = dict()\n",
    "            self.g = 0\n",
    "            self.cores = {core_n : {\"task\" : -1, \"task_end_time\" : 0} for core_n in range(n_cores)}\n",
    "            self.hist = ''  \n",
    "            self.schedule = dict()\n",
    "            \n",
    "        else:\n",
    "            self.parent = parent\n",
    "            task_end_time = task_end_time\n",
    "            self.tasks_done_time = parent.tasks_done_time.copy()\n",
    "            self.tasks_done_time[task_to_add] = task_end_time\n",
    "\n",
    "            self.cores = parent.cores.copy()\n",
    "            self.cores[core_where_to_add] = {\"task\" : task_to_add, \"task_end_time\" : task_end_time}\n",
    "                \n",
    "            self.g = max(parent.g, task_end_time)\n",
    "            \n",
    "            self.schedule = parent.schedule.copy()\n",
    "            self.schedule[task_to_add] = (time_task_start, task_end_time, core_where_to_add)\n",
    "            self.hist = parent.hist + f\"|Task {task_to_add} start at time {time_task_start} on core {core_where_to_add} \"\n",
    "                 \n",
    "    def __repr__(self):\n",
    "        string = '[' + ','.join([n2letter(task) for task in self.tasks_done_time]) + ']'\n",
    "        string += ''.join([f\"({core['task']} end at {core['task_end_time']})\" for core in self.cores.values()])\n",
    "        return string    \n",
    "    \n",
    "    #Node-schedule method\n",
    "    def __lt__(self, node):\n",
    "        return self.f < node.f\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return int(self.f)\n",
    "        \n",
    "    def set_of_core(self):\n",
    "        return set([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "    def compute_g(self):\n",
    "        return max([core[\"task_end_time\"] for core in self.cores.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "class Graph:\n",
    "    def __init__(self, path, n_cores = 2, alpha = 1):\n",
    "        self.tasks, self.task_count = read_data(path) \n",
    "        self.tasks_to_child, self.tasks_to_parent = load_dependencies(self.tasks)\n",
    "        self.tasks_to_sbl = sbl(self.tasks, self.tasks_to_child, self.tasks_to_parent)\n",
    "        self.n_cores = n_cores\n",
    "        self.alpha = alpha\n",
    "        self.root = Node(n_cores)\n",
    "    \n",
    "    def equal(self, node1, node2):\n",
    "        '''Return whether a node is equal to another. Two nodes are considered equal if they have completed the same tasks and if all their cores stop working at same time.\n",
    "        '''\n",
    "        if node1.g != node2.g:\n",
    "            return False       \n",
    "        if node1.tasks_done_time != node2.tasks_done_time:\n",
    "            return False\n",
    "        return node1.set_of_core() == node2.set_of_core()\n",
    "\n",
    "    def cost(self, current, next):\n",
    "        '''Return the cost of going from self to child_node, a child node of self\n",
    "        '''\n",
    "        res = next.g - current.g\n",
    "        if res < 0:\n",
    "            raise Exception(\"Cost difference is negative\")\n",
    "        return res\n",
    "    \n",
    "    def is_solved(self, node):\n",
    "        '''Return whether a node is a full schedule'''\n",
    "        return len(node.tasks_done_time) == self.task_count\n",
    "    \n",
    "    def h(self, node):\n",
    "        '''Estimated remaining time of the node-schedule for reaching a terminal node. Must understimate true value.\n",
    "        '''\n",
    "        successor_tasks = list()\n",
    "        for task, info in self.tasks.items():\n",
    "            if task in node.tasks_done_time: #On passe les taches déjà ajoutées\n",
    "                continue    #O(n_task)\n",
    "            if not all([task_required in node.tasks_done_time for task_required in info['Dependencies']]):   #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "                continue    #O(n_task * n_depencies_of_node)\n",
    "            \n",
    "            pass_task = False\n",
    "            for task_required in info['dependencies']:\n",
    "                if task_required not in node.tasks_done_time:\n",
    "                    pass_task = True\n",
    "                    break\n",
    "            if pass_task:\n",
    "                continue\n",
    "            \n",
    "            successor_tasks.append(task)\n",
    "        if len(successor_tasks) == 0:\n",
    "            return 0\n",
    "        return self.alpha*max([self.tasks_to_sbl[task] for task in successor_tasks])\n",
    "    \n",
    "    def n_successors(self, node):\n",
    "        return len(self.successors(node))\n",
    "    \n",
    "    def successor(self, node, i):\n",
    "        return sorted(self.successors(node), key = lambda n: n.g + self.h(n))[i]\n",
    "    \n",
    "    def successors(self, node):\n",
    "        childs = list()\n",
    "        #On regarde toutes les tâches qu'on va tenter de rajouter\n",
    "        for task, info in self.tasks.items():\n",
    "            \n",
    "            #On passe les taches déjà ajoutées\n",
    "            if task in node.tasks_done_time: \n",
    "                continue\n",
    "            \n",
    "            #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "            if not all([task_required in node.tasks_done_time for task_required in info['Dependencies']]): \n",
    "                continue\n",
    "            \n",
    "            #On calcul le temps ou toutes les dépendances de task seront terminés par les coeurs   \n",
    "            time_all_tasks_done = max([0] + [node.tasks_done_time[task_required] for task_required in info['Dependencies']])\n",
    "                                         \n",
    "            for core_n, core in node.cores.items():\n",
    "                #On ne commence à faire la task que lorsque toutes les dépendances sont calculées et que le core est disponible.\n",
    "                time_core_available = core[\"task_end_time\"]\n",
    "                time_task_start = max(time_all_tasks_done, time_core_available)\n",
    "                task_end_time = time_task_start + self.tasks[task]['Data']\n",
    "                child = Node(n_cores = self.n_cores, parent = node, task_to_add=task, core_where_to_add=core_n, time_task_start=time_task_start, task_end_time=task_end_time)    \n",
    "                childs.append(child)\n",
    "                \n",
    "        return childs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def h(n):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def search(stack, bound, depth):\n",
    "    indexes = [0]\n",
    "    while (len(stack)):\n",
    "        node = stack[-1]\n",
    "        index = indexes[-1]\n",
    "\n",
    "        f = node.g + graph.h(node)\n",
    "\n",
    "        if graph.is_solved(node):\n",
    "            return sorted(graph.successors(stack[-2]), key=lambda n: n.g)[0]\n",
    "        \n",
    "        if len(stack) == depth:\n",
    "            return sorted(graph.successors(stack[-2]), key=lambda n: n.g + graph.h(n))[0]\n",
    "\n",
    "        if f > bound:\n",
    "            stack.pop()\n",
    "            indexes.pop()\n",
    "            continue\n",
    "\n",
    "        if index >= graph.n_successors(node):\n",
    "            stack.pop()\n",
    "            indexes.pop()\n",
    "            continue\n",
    "        \n",
    "        succ = graph.successor(node, index)\n",
    "        indexes[-1] = index + 1\n",
    "        stack.append(succ)\n",
    "        indexes.append(0)\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "def ida_star(depth = np.inf):\n",
    "    bound = graph.h(graph.root)*2\n",
    "    stack = [graph.root]\n",
    "    t = search(stack, bound, depth)\n",
    "    if isinstance(t, Node):\n",
    "        print('Done')\n",
    "        return t\n",
    "    print('Not found')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "read_data(\"../Graphs/smallComplex.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_72333/3428503505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Graphs/xsmallComplex.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mida_star\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/tmp/ipykernel_72333/1110979764.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, n_cores, alpha)\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_sbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msbl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_parent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object\n",
      "[0:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_72332/3428503505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Graphs/xsmallComplex.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mida_star\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/tmp/ipykernel_72332/1110979764.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, n_cores, alpha)\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_sbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msbl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_parent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object\n",
      "[3:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_72335/3428503505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Graphs/xsmallComplex.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mida_star\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/tmp/ipykernel_72335/1110979764.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, n_cores, alpha)\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_sbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msbl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_parent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object\n",
      "[2:execute]\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_72334/3428503505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Graphs/xsmallComplex.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mida_star\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/tmp/ipykernel_72334/1110979764.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, n_cores, alpha)\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_sbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msbl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_to_parent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object\n"
     ]
    },
    {
     "ename": "AlreadyDisplayedError",
     "evalue": "4 errors",
     "output_type": "error",
     "traceback": [
      "4 errors"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "graph = Graph('Graphs/xsmallComplex.json', 6, 1)\n",
    "final_node = ida_star()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch IDA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px:   0%|          | 0/4 [00:00<?, ?tasks/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[stdout:0] ['2365', '3532', '3538']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:1] ['2365', '3532', '3538']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:3] ['2365', '3532', '3538']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[stdout:2] ['2365', '3532', '3538']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%px: 100%|██████████| 4/4 [00:00<00:00, 38.04tasks/s]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "path = ida_star(graph.roots[0], '3538')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping controller\n",
      "Failed to remove C:\\Users\\Oussama Janaheddine\\.ipython\\profile_default\\log\\ipcontroller-1647865219-201z-12692.log: [WinError 2] Le fichier spécifié est introuvable: 'C:\\\\Users\\\\Oussama Janaheddine\\\\.ipython\\\\profile_default\\\\log\\\\ipcontroller-1647865219-201z-12692.log'\n",
      "Controller stopped: {'exit_code': 1, 'pid': 8552, 'identifier': 'ipcontroller-1647865219-201z-12692'}\n",
      "Stopping engine(s): 1647865220\n",
      "Failed to remove C:\\Users\\Oussama Janaheddine\\.ipython\\profile_default\\log\\ipengine-1647865219-201z-1647865220-12692.log: [WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'C:\\\\Users\\\\Oussama Janaheddine\\\\.ipython\\\\profile_default\\\\log\\\\ipengine-1647865219-201z-1647865220-12692.log'\n",
      "Failed to remove C:\\Users\\Oussama Janaheddine\\.ipython\\profile_default\\log\\ipengine-1647865219-201z-1647865220-12692.log: [WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'C:\\\\Users\\\\Oussama Janaheddine\\\\.ipython\\\\profile_default\\\\log\\\\ipengine-1647865219-201z-1647865220-12692.log'\n",
      "engine set stopped 1647865220: {'exit_code': 1, 'pid': 6528, 'identifier': 'ipengine-1647865219-201z-1647865220-12692'}\n"
     ]
    }
   ],
   "source": [
    "await cluster.stop_cluster()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe6933227b6ff62866ee779fb700ff9b140c0fa454ba86f0194dc57655bf90d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('ipyparallel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
