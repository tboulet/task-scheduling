{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of IDA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import bisect\n",
    "from collections import defaultdict\n",
    "from itertools import cycle\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import n_cores, filename, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2letter(n):\n",
    "    '''0 to 'a', 1 to 'b', ... '''\n",
    "    return str(n)\n",
    "    \n",
    "def string2duration(string):\n",
    "    ''' \"01:50:19.3177493\" to duration in seconds'''\n",
    "    date =  datetime.strptime(string.split('.')[0], \"%H:%M:%S\")\n",
    "    return date.second + 60*date.minute + 3600*date.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    global task_count\n",
    "    global tasks\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    nodes = data['nodes']\n",
    "    tasks = dict()\n",
    "    for task_str, info in nodes.items():\n",
    "        task = int(task_str)\n",
    "        tasks[task] = {'Data' : string2duration(info['Data']), 'Dependencies' : info['Dependencies']}\n",
    "    task_count = len(tasks)\n",
    "    print(\"Data loaded successfully. Number of tasks: \" + str(task_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dependencies():\n",
    "    global task2childs\n",
    "    global task2parents\n",
    "    #Tasks to child tasks / Tasks to parents / Task is terminal / Task is inital\n",
    "    task2childs = {task : list() for task in tasks}\n",
    "    task2parents = {task : list() for task in tasks}\n",
    "    for task, info in tasks.items():\n",
    "        #Add childs\n",
    "        list_task_parents = info['Dependencies']\n",
    "        for task_parent in list_task_parents:\n",
    "            task2childs[task_parent].append(task)\n",
    "        #Add parents\n",
    "        task2parents[task] = tasks[task]['Dependencies']\n",
    "    \n",
    "def task_is_terminal(task: int):\n",
    "    return len(task2childs[task]) == 0\n",
    "def task_is_inital(task: int):\n",
    "    return len(task2parents[task]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Bottom Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_static_bottom_level(task : int, task2sbl):\n",
    "    task_duration = tasks[task][\"Data\"]\n",
    "    if task_is_terminal(task):\n",
    "        sbl = task_duration\n",
    "    else:\n",
    "        list_sbl_child = list()\n",
    "        for task_child in task2childs[task]:\n",
    "            if task_child in task2sbl:\n",
    "                sbl_child = task2sbl[task_child]\n",
    "            else:\n",
    "                sbl_child = save_static_bottom_level(task_child, task2sbl)\n",
    "            list_sbl_child.append(sbl_child)\n",
    "        sbl = max(list_sbl_child) + task_duration\n",
    "                \n",
    "    task2sbl[task] = sbl\n",
    "    return sbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbl():\n",
    "    global task2sbl\n",
    "    task2sbl = {}\n",
    "    for task in tasks:\n",
    "        if task_is_inital(task):\n",
    "            save_static_bottom_level(task, task2sbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.tasks = tasks\n",
    "        self.tasks_to_sbl = task2sbl\n",
    "        self.tasks_to_parent = task2parents\n",
    "        self.tasks_to_child = task2childs\n",
    "        self.n_cores = n_cores\n",
    "        self.nodes = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, graph = None,  parent = None, task_to_add = None, core_where_to_add = None, time_task_start = None):\n",
    "        '''Create a Node object ie a partial scheduling\n",
    "        parent = parent Node, None if root\n",
    "        task_to_add : task added to the partial schedule\n",
    "        core_where_to_add : core where to do task\n",
    "        time_task_start : instant where the core will start computing the task\n",
    "        '''   \n",
    "\n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.graph = graph\n",
    "            self.tasks_done_time = dict()\n",
    "            self.cores = {core_n : {\"task\" : -1, \"task_end_time\" : 0} for core_n in range(n_cores)}\n",
    "            \n",
    "            self.g = 0\n",
    "            self.f = self.h()\n",
    "                   \n",
    "            self.hist = ''  \n",
    "            self.schedule = dict()\n",
    "            \n",
    "        else:\n",
    "            self.parent = parent\n",
    "            if graph:\n",
    "                self.graph = graph\n",
    "            else:\n",
    "                self.graph = self.parent.graph\n",
    "            task_end_time = time_task_start + self.graph.tasks[task_to_add]['Data']\n",
    "            self.tasks_done_time = parent.tasks_done_time.copy()\n",
    "            self.tasks_done_time[task_to_add] = task_end_time\n",
    "\n",
    "            self.cores = parent.cores.copy()\n",
    "            self.cores[core_where_to_add] = {\"task\" : task_to_add, \"task_end_time\" : task_end_time}\n",
    "                \n",
    "            self.g = max(parent.g, task_end_time)\n",
    "            # self.f = max(self.g + self.h(), parent.f)\n",
    "            self.f = self.g + self.h()\n",
    "            \n",
    "            self.schedule = parent.schedule.copy()\n",
    "            self.schedule[task_to_add] = (time_task_start, task_end_time, core_where_to_add)\n",
    "            self.hist = parent.hist + f\"|Task {task_to_add} start at time {time_task_start} on core {core_where_to_add} \"\n",
    "                 \n",
    "    def __repr__(self):\n",
    "        string = '[' + ','.join([n2letter(task) for task in self.tasks_done_time]) + ']'\n",
    "        string += ''.join([f\"({core['task']} end at {core['task_end_time']})\" for core in self.cores.values()])\n",
    "        return string\n",
    "    \n",
    "    def is_solved(self):\n",
    "        '''Return whether a node is a full schedule'''\n",
    "        return len(self.tasks_done_time) == task_count\n",
    "    \n",
    "    def successors(self):                     \n",
    "        '''Create and return list of child node of self'''\n",
    "        childs = list()\n",
    "        \n",
    "        #On regarde toutes les tâches qu'on va tenter de rajouter\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            \n",
    "            #On passe les taches déjà ajoutées\n",
    "            if task in self.tasks_done_time: \n",
    "                continue\n",
    "            \n",
    "            #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]): \n",
    "                continue\n",
    "            \n",
    "            #On calcul le temps ou toutes les dépendances de task seront terminés par les coeurs   \n",
    "            time_all_tasks_done = max([0] + [self.tasks_done_time[task_required] for task_required in info['Dependencies']])\n",
    "                                         \n",
    "            for core_n, core in self.cores.items():\n",
    "                #On ne commence à faire la task que lorsque toutes les dépendances sont calculées et que le core est disponible.\n",
    "                time_core_available = core[\"task_end_time\"]\n",
    "                time_task_start = max(time_all_tasks_done, time_core_available)\n",
    "                \n",
    "                child = Node(parent = self, task_to_add=task, core_where_to_add=core_n, time_task_start=time_task_start)    \n",
    "                childs.append(child)\n",
    "                \n",
    "        return sorted(childs, key = lambda node: node.f)\n",
    "        \n",
    "    def cost(self, child_node):\n",
    "        '''Return the cost of going from self to child_node, a child node of self\n",
    "        '''\n",
    "        res = child_node.g - self.g\n",
    "        if res < 0:\n",
    "            raise Exception(\"Cost difference is negative\")\n",
    "        return res\n",
    "    \n",
    "    def h(self):\n",
    "        '''Estimated remaining time of the node-schedule for reaching a terminal node. Must understimate true value.\n",
    "        '''\n",
    "        successor_tasks = list()\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            if task in self.tasks_done_time: #On passe les taches déjà ajoutées\n",
    "                continue\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]):   #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "                continue\n",
    "            successor_tasks.append(task)\n",
    "        if len(successor_tasks) == 0:\n",
    "            return 0\n",
    "        return alpha*max([self.graph.tasks_to_sbl[task] for task in successor_tasks])\n",
    "        \n",
    "    \n",
    "    #Node-schedule method\n",
    "    def __lt__(self, node):\n",
    "        return self.f < node.f\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return int(self.f)\n",
    "        \n",
    "    def __eq__(self, node):\n",
    "        '''Return whether a node is equal to another. Two nodes are considered equal if they have completed the same tasks and if all their cores stop working at same time.\n",
    "        '''\n",
    "        if self.g != node.g:\n",
    "            return False       \n",
    "        if self.tasks_done_time != node.tasks_done_time:\n",
    "            return False\n",
    "        return self.set_of_core() == node.set_of_core()\n",
    "        \n",
    "    def set_of_core(self):\n",
    "        return set([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "    def compute_g(self):\n",
    "        return max([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search to goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_goal(path, g, bound, goal):\n",
    "    node = path[-1]\n",
    "    f = g + node.h()\n",
    "    if f > bound:\n",
    "        return f\n",
    "    if node == goal:\n",
    "        return node\n",
    "    minimum = np.inf\n",
    "    for succ in node.successors():\n",
    "        if succ not in path:\n",
    "            path.append(succ)\n",
    "            t = search_goal(path, g + node.cost(succ), bound, goal)\n",
    "            if isinstance(t, Node):\n",
    "                return t\n",
    "            elif t < minimum:\n",
    "                minimum = t\n",
    "            path.pop()\n",
    "    return minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search until solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_solved(path, g, bound):\n",
    "    node = path[-1]\n",
    "    f = g + node.h()\n",
    "    if f > bound:\n",
    "        return f\n",
    "    if node.is_solved():\n",
    "        best_node = sorted(path[-2].successors(), key = lambda n : n.g)[0]\n",
    "        path[-1] = best_node\n",
    "        return best_node\n",
    "    minimum = np.inf\n",
    "    for succ in node.successors():\n",
    "        if succ not in path:\n",
    "            path.append(succ)\n",
    "            t = search_solved(path, g + node.cost(succ), bound)\n",
    "            if isinstance(t, Node):\n",
    "                return t\n",
    "            elif t < minimum:\n",
    "                minimum = t\n",
    "            path.pop()\n",
    "    return minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ida_star(root, goal = None):\n",
    "    bound = root.h()*2\n",
    "    path = [root]\n",
    "    if goal:\n",
    "        t = search_goal(path, 0, bound, goal)\n",
    "    else:\n",
    "        t = search_solved(path, 0, bound)\n",
    "    if isinstance(t, Node):\n",
    "        return t\n",
    "    return 'Not found'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(lst: list[str]):\n",
    "    x = lst.pop(0)\n",
    "    lst.append(x)\n",
    "    return x\n",
    "\n",
    "def plot_schedule(node, critical_path=[]):\n",
    "    schedule = node.schedule\n",
    "    colors_by_proc = defaultdict(lambda:\n",
    "        ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'])\n",
    "    for id, (start, end, proc) in schedule.items():\n",
    "        # cycle through the colors for this processor\n",
    "        color = cycle(colors_by_proc[proc])\n",
    "        colors_by_proc[proc].append(color)\n",
    "        \n",
    "        # handle critical path nodes\n",
    "        if id in critical_path:\n",
    "            critical_kwargs = {\n",
    "                'edgecolor': 'red',\n",
    "                'lw': 2,\n",
    "                'zorder': 100,\n",
    "            }\n",
    "        else:\n",
    "            critical_kwargs = {}\n",
    "        \n",
    "        # blot the bar and text\n",
    "        plt.broken_barh([(start, end-start)],\n",
    "                        (proc-.4, .8),\n",
    "                        facecolors=color,\n",
    "                        **critical_kwargs)\n",
    "        plt.annotate(str(id),\n",
    "                        xy=((start+end)/2, proc),\n",
    "                        ha='center',\n",
    "                        va='center',\n",
    "                        zorder=101)\n",
    "    plt.yticks(list(colors_by_proc.keys()), [f'Proc {proc}' for proc in colors_by_proc.keys()])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(node):\n",
    "    solution_df = pd.DataFrame.from_dict(node.schedule, orient='index', columns=['start', 'end', 'core'])\n",
    "    task_df = pd.DataFrame.from_dict(task2sbl, orient='index', columns=['sbl'])\n",
    "    score = solution_df['end'].max()\n",
    "    best_time = task_df['sbl'].max()\n",
    "    if best_time > score:\n",
    "        return False\n",
    "\n",
    "    for task in solution_df.index:\n",
    "        for parent in tasks[task]['Dependencies']:\n",
    "            if solution_df.loc[parent]['end'] > solution_df.loc[task]['start']:\n",
    "                return False\n",
    "\n",
    "    return (100*(score - best_time)/best_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Number of tasks: 10\n"
     ]
    }
   ],
   "source": [
    "read_data(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch IDA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,2,3,5,4,7,8,10,6,9](9 end at 23295)(6 end at 18744)\n"
     ]
    }
   ],
   "source": [
    "load_dependencies()\n",
    "sbl()\n",
    "graph = Graph()\n",
    "final_node = ida_star(Node(graph=graph))\n",
    "print(final_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_schedule(final_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.10824142326664"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(final_node)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69cf9839690728ef7ab10dcb5f4b78192faf9c3916570632a7583891615174d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cs2021')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
