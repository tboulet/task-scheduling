{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/smallRandom.json\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import bisect\n",
    "\n",
    "from config import filename, n_cores\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def n2letter(n):\n",
    "    '''0 to 'a', 1 to 'b', ... '''\n",
    "    return chr(96+n)\n",
    "\n",
    "def string2duration(string):\n",
    "    ''' \"01:50:19.3177493\" to duration in seconds'''\n",
    "    return 3600*int(string[:2]) + 60*int(string[3:5]) + int(string[6:8])  #Duration is int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Number of tasks: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'Data': 2843, 'Dependencies': []},\n",
       " 2: {'Data': 3656, 'Dependencies': [1]},\n",
       " 3: {'Data': 2741, 'Dependencies': [1]},\n",
       " 4: {'Data': 4166, 'Dependencies': [1]},\n",
       " 5: {'Data': 5065, 'Dependencies': [2]},\n",
       " 6: {'Data': 5116, 'Dependencies': [4]},\n",
       " 7: {'Data': 3878, 'Dependencies': [2]},\n",
       " 8: {'Data': 3596, 'Dependencies': [5]},\n",
       " 9: {'Data': 5252, 'Dependencies': [7]},\n",
       " 10: {'Data': 2883, 'Dependencies': [8]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(path):\n",
    "    global task_count\n",
    "    global tasks\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    nodes = data['nodes']\n",
    "    tasks = dict()\n",
    "    for task_str, info in nodes.items():\n",
    "        task = int(task_str)\n",
    "        tasks[task] = {'Data' : string2duration(info['Data']), 'Dependencies' : info['Dependencies']}\n",
    "    task_count = len(tasks)\n",
    "    print(\"Data loaded successfully. Number of tasks: \" + str(task_count))\n",
    "\n",
    "read_data(filename)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [2, 3, 4], 2: [5, 7], 3: [], 4: [6], 5: [8], 6: [], 7: [9], 8: [10], 9: [], 10: []}\n",
      "{1: [], 2: [1], 3: [1], 4: [1], 5: [2], 6: [4], 7: [2], 8: [5], 9: [7], 10: [8]}\n"
     ]
    }
   ],
   "source": [
    "#Tasks to child tasks / Tasks to parents / Task is terminal / Task is inital\n",
    "task2childs = {task : list() for task in tasks}\n",
    "task2parents = {task : list() for task in tasks}\n",
    "for task, info in tasks.items():\n",
    "    #Add childs\n",
    "    list_task_parents = info['Dependencies']\n",
    "    for task_parent in list_task_parents:\n",
    "        task2childs[task_parent].append(task)\n",
    "    #Add parents\n",
    "    task2parents[task] = tasks[task]['Dependencies']\n",
    "    \n",
    "def task_is_terminal(task: int):\n",
    "    return len(task2childs[task]) == 0\n",
    "def task_is_inital(task: int):\n",
    "    return len(task2parents[task]) == 0\n",
    "\n",
    "print(task2childs)\n",
    "print(task2parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 2883,\n",
       " 8: 6479,\n",
       " 5: 11544,\n",
       " 9: 5252,\n",
       " 7: 9130,\n",
       " 2: 15200,\n",
       " 3: 2741,\n",
       " 6: 5116,\n",
       " 4: 9282,\n",
       " 1: 18043}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2sbl = {}\n",
    "\n",
    "def save_static_bottom_level(task : int):\n",
    "    task_duration = tasks[task][\"Data\"]\n",
    "    if task_is_terminal(task):\n",
    "        sbl = task_duration\n",
    "    else:\n",
    "        list_sbl_child = list()\n",
    "        for task_child in task2childs[task]:\n",
    "            if task_child in task2sbl:\n",
    "                sbl_child = task2sbl[task_child]\n",
    "            else:\n",
    "                sbl_child = save_static_bottom_level(task_child)\n",
    "            list_sbl_child.append(sbl_child)\n",
    "        sbl = max(list_sbl_child) + task_duration\n",
    "                \n",
    "    task2sbl[task] = sbl\n",
    "    return sbl\n",
    "\n",
    "for task in tasks:\n",
    "    if task_is_inital(task):\n",
    "        save_static_bottom_level(task)\n",
    "        \n",
    "task2sbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tasks = tasks\n",
    "        self.tasks_to_sbl = task2sbl\n",
    "        self.tasks_to_parent = task2parents\n",
    "        self.tasks_to_child = task2childs\n",
    "        self.n_cores = 2\n",
    "        self.nodes = list()\n",
    "\n",
    "graph = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    graph = graph\n",
    "    \n",
    "    def __init__(self, parent = None, task_to_add = None, core_where_to_add = None, time_task_start = None):\n",
    "        '''Create a Node object ie a partial scheduling\n",
    "        parent = parent Node, None if root\n",
    "        task_to_add : task added to the partial schedule\n",
    "        core_where_to_add : core where to do task\n",
    "        time_task_start : instant where the core will start computing the task\n",
    "        '''        \n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.tasks_done_time = dict()\n",
    "            self.cores = {core_n : {\"task\" : -1, \"task_end_time\" : 0} for core_n in range(n_cores)}\n",
    "            \n",
    "            self.g = 0\n",
    "            self.f = self.h()\n",
    "                   \n",
    "            self.hist = ''  \n",
    "            self.schedule = dict()\n",
    "            \n",
    "        else:\n",
    "            task_end_time = time_task_start + self.graph.tasks[task_to_add]['Data']\n",
    "            \n",
    "            self.parent = parent\n",
    "            self.tasks_done_time = parent.tasks_done_time.copy()\n",
    "            self.tasks_done_time[task_to_add] = task_end_time\n",
    "\n",
    "            self.cores = parent.cores.copy()\n",
    "            self.cores[core_where_to_add] = {\"task\" : task_to_add, \"task_end_time\" : task_end_time}\n",
    "                \n",
    "            self.g = self.compute_g()\n",
    "            self.f = max(self.g + self.h(), parent.f)\n",
    "            \n",
    "            \n",
    "            self.schedule = parent.schedule.copy()\n",
    "            self.schedule[task_to_add] = (time_task_start, task_end_time, core_where_to_add)\n",
    "            self.hist = parent.hist + f\"|Task {task_to_add} start at time {time_task_start} on core {core_where_to_add} \"\n",
    "                 \n",
    "    def __repr__(self):\n",
    "        string = '[' + ','.join([n2letter(task) for task in self.tasks_done_time]) + ']'\n",
    "        string += ''.join([f\"({core['task']} end at {core['task_end_time']})\" for core in self.cores.values()])\n",
    "        return string\n",
    "            \n",
    "    def is_goal(self):\n",
    "        '''Return whether a node is a full schedule'''\n",
    "        return len(self.tasks_done_time) == task_count\n",
    "    \n",
    "    def successors(self):                     \n",
    "        '''Create and return list of child node of self'''\n",
    "        childs = list()\n",
    "        \n",
    "        #On regarde toutes les tâches qu'on va tenter de rajouter\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            \n",
    "            #On passe les taches déjà ajoutées\n",
    "            if task in self.tasks_done_time: \n",
    "                continue\n",
    "            \n",
    "            #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]): \n",
    "                continue\n",
    "            \n",
    "            #On calcul le temps ou toutes les dépendances de task seront terminés par les coeurs   \n",
    "            time_all_tasks_done = max([0] + [self.tasks_done_time[task_required] for task_required in info['Dependencies']])\n",
    "                                         \n",
    "            for core_n, core in self.cores.items():\n",
    "                #On ne commence à faire la task que lorsque toutes les dépendances sont calculées et que le core est disponible.\n",
    "                time_core_available = core[\"task_end_time\"]\n",
    "                time_task_start = max(time_all_tasks_done, time_core_available)\n",
    "                \n",
    "                child = Node(parent = self, task_to_add=task, core_where_to_add=core_n, time_task_start=time_task_start)    \n",
    "                childs.append(child)\n",
    "                \n",
    "        return sorted(childs, key = lambda node: node.f)\n",
    "        \n",
    "    def cost(self, child_node):\n",
    "        '''Return the cost of going from self to child_node, a child node of self\n",
    "        '''\n",
    "        res = child_node.g - self.g\n",
    "        if res < 0:\n",
    "            raise Exception(\"Cost difference is negative\")\n",
    "        return res\n",
    "    \n",
    "    def h(self):\n",
    "        '''Estimated remaining time of the node-schedule for reaching a terminal node. Must understimate true value.\n",
    "        '''\n",
    "        successor_tasks = list()\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            if task in self.tasks_done_time: #On passe les taches déjà ajoutées\n",
    "                continue\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]):   #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "                continue\n",
    "            successor_tasks.append(task)\n",
    "        if len(successor_tasks) == 0:\n",
    "            return 0\n",
    "        return max([self.graph.tasks_to_sbl[task] for task in successor_tasks])\n",
    "        \n",
    "    \n",
    "    #Node-schedule method\n",
    "    def __lt__(self, node):\n",
    "        return self.f < node.f\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return int(self.f)\n",
    "        \n",
    "    def __eq__(self, node):\n",
    "        '''Return whether a node is equal to another. Two nodes are considered equal if they have completed the same tasks and if all their cores stop working at same time.\n",
    "        '''\n",
    "        if self.g != node.g:\n",
    "            return False       \n",
    "        if self.tasks_done_time != node.tasks_done_time:\n",
    "            return False\n",
    "        # if set(self.cores.values()) != set(node.cores.values()):\n",
    "        #     return False\n",
    "        return self.set_of_core() == node.set_of_core()\n",
    "        \n",
    "    def set_of_core(self):\n",
    "        return set([(core_n, core[\"task_end_time\"]) for core_n, core in self.cores.items()])\n",
    "    \n",
    "    def compute_g(self):\n",
    "        return max([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "# r = Node()\n",
    "# x,y = r.successors()\n",
    "# a,b,c,d,e,f, *_ = x.successors()[0].successors()\n",
    "# g, h, i, j, k, l, *_ = y.successors()[0].successors()\n",
    "\n",
    "# #Test successors\n",
    "# print(a, b, c, d, e, f, sep = '\\n')\n",
    "# print()\n",
    "# print(g, h, i, j, k, l, sep = '\\n')\n",
    "# print()\n",
    "\n",
    "# #Test __eq__\n",
    "# for i in (g, h, i, j, k, l):\n",
    "#     for j in (a, b, c, d, e, f):\n",
    "#         if i == j:\n",
    "#             print(i, j)\n",
    "\n",
    "# #Test cost\n",
    "# x.cost(a)\n",
    "\n",
    "# #Test h\n",
    "# print(r.h())\n",
    "# print(x.h())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import queue\n",
    "import random as rd\n",
    "\n",
    "class A_star():\n",
    "    def __init__(self, root, graph):\n",
    "        self.root = root\n",
    "        self.graph = graph\n",
    "\n",
    "    def find_best_path(self, max_time = float('inf')):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        OPEN_QUEUE = queue.PriorityQueue()\n",
    "        OPEN_QUEUE.put(self.root)       #Open queue, pile of most urgent node to be evaluated\n",
    "        OPEN_SET = {self.root}   #Open set, more efficient way to compute if a node is in the open list\n",
    "        CLOSED_SET = set()            #Closed list, list of already explored node\n",
    "        \n",
    "        while not OPEN_QUEUE.empty():\n",
    "            if time.time() - t0 > max_time:\n",
    "                print('Time out')\n",
    "                return\n",
    "\n",
    "            current = OPEN_QUEUE.get()\n",
    "            OPEN_SET.remove(current)\n",
    "            CLOSED_SET.add(current)\n",
    "            if current.is_goal():   #If we reach a final node, it is the optimal solution and we return it\n",
    "                return current\n",
    "\n",
    "            for child in current.successors():\n",
    "\n",
    "                if child in CLOSED_SET:    #We pass the node already visited\n",
    "                    continue\n",
    "                    \n",
    "                if child in OPEN_SET:      #We pass the node already waiting to be visited (note: in A* general, we need to recompute child.g and child.parent here, but for us child.g only depends on child (not on parent))\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    # child.g = current.g + current.cost(child)     #General method. In our case, node.g does not depend on the path and the parent node\n",
    "                    OPEN_QUEUE.put(child)\n",
    "                    OPEN_SET.add(child)\n",
    "                    \n",
    "        raise Exception(\"No path from root to a terminal node\")\n",
    "    \n",
    "# A_star(root = Node(), graph=graph).find_best_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a,b,d,e,g,h,i,f,c,j](10 end at 22440)(6 end at 20276)\n",
      "         441790 function calls in 0.229 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     4346    0.069    0.000    0.077    0.000 <ipython-input-8-3705135e2650>:85(h)\n",
      "   194078    0.041    0.000    0.058    0.000 <ipython-input-8-3705135e2650>:107(__eq__)\n",
      "        1    0.019    0.019    0.229    0.229 <ipython-input-9-6290cbdc01d0>:10(find_best_path)\n",
      "     4346    0.013    0.000    0.101    0.000 <ipython-input-8-3705135e2650>:4(__init__)\n",
      "     3493    0.011    0.000    0.032    0.000 {method 'add' of 'set' objects}\n",
      "    16306    0.011    0.000    0.017    0.000 <ipython-input-8-3705135e2650>:118(set_of_core)\n",
      "      724    0.010    0.000    0.116    0.000 <ipython-input-8-3705135e2650>:49(successors)\n",
      "    16306    0.005    0.000    0.005    0.000 <ipython-input-8-3705135e2650>:119(<listcomp>)\n",
      "     4346    0.004    0.000    0.007    0.000 <ipython-input-8-3705135e2650>:121(compute_g)\n",
      "     2769    0.004    0.000    0.013    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:122(put)\n",
      "    19549    0.004    0.000    0.004    0.000 {built-in method builtins.max}\n",
      "    13038    0.003    0.000    0.003    0.000 {method 'copy' of 'dict' objects}\n",
      "    13719    0.003    0.000    0.003    0.000 <ipython-input-8-3705135e2650>:101(__lt__)\n",
      "    13818    0.003    0.000    0.003    0.000 <ipython-input-8-3705135e2650>:92(<listcomp>)\n",
      "     3494    0.002    0.000    0.004    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:351(notify)\n",
      "    12835    0.002    0.000    0.002    0.000 <ipython-input-8-3705135e2650>:104(__hash__)\n",
      "    23549    0.002    0.000    0.002    0.000 {method 'items' of 'dict' objects}\n",
      "    16727    0.002    0.000    0.002    0.000 {built-in method builtins.all}\n",
      "     4338    0.002    0.000    0.002    0.000 <ipython-input-8-3705135e2650>:97(<listcomp>)\n",
      "     2769    0.002    0.000    0.003    0.000 {built-in method _heapq.heappush}\n",
      "    14882    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "      725    0.001    0.000    0.003    0.000 {built-in method _heapq.heappop}\n",
      "      725    0.001    0.000    0.007    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:154(get)\n",
      "      725    0.001    0.000    0.003    0.000 {method 'remove' of 'set' objects}\n",
      "      724    0.001    0.000    0.002    0.000 {built-in method builtins.sorted}\n",
      "     4346    0.001    0.000    0.001    0.000 <ipython-input-8-3705135e2650>:122(<listcomp>)\n",
      "     3494    0.001    0.000    0.002    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:271(_is_owned)\n",
      "     3494    0.001    0.000    0.002    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:256(__enter__)\n",
      "     3494    0.001    0.000    0.001    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:259(__exit__)\n",
      "     2769    0.001    0.000    0.004    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:235(_put)\n",
      "     3494    0.001    0.000    0.001    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "     6521    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "      725    0.001    0.000    0.001    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:97(empty)\n",
      "     3494    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "     2909    0.001    0.000    0.001    0.000 <ipython-input-8-3705135e2650>:61(<listcomp>)\n",
      "     4346    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "     2173    0.000    0.000    0.000    0.000 <ipython-input-8-3705135e2650>:65(<listcomp>)\n",
      "     4219    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "     4346    0.000    0.000    0.000    0.000 <ipython-input-8-3705135e2650>:75(<lambda>)\n",
      "     1450    0.000    0.000    0.001    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:232(_qsize)\n",
      "      725    0.000    0.000    0.000    0.000 <ipython-input-8-3705135e2650>:45(is_goal)\n",
      "      725    0.000    0.000    0.004    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:238(_get)\n",
      "      726    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:34(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:228(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\cProfile.py:117(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:229(_init)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x23c8913cdf0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "root = Node()\n",
    "a_star = A_star(root = root, graph=graph)\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    final_node = a_star.find_best_path()\n",
    "\n",
    "print(final_node)\n",
    "stats = pstats.Stats(pr)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(filename='profiling.prof')\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (0, 2843, 1), 2: (2843, 6499, 0), 4: (2843, 7009, 1), 5: (6499, 11564, 0), 7: (7009, 10887, 1), 8: (11564, 15160, 1), 9: (11564, 16816, 0), 6: (15160, 20276, 1), 3: (16816, 19557, 0), 10: (19557, 22440, 0)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import cycle\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "schedule = final_node.schedule\n",
    "\n",
    "def cycle(lst: list[str]) -> str:\n",
    "    x = lst.pop(0)\n",
    "    lst.append(x)\n",
    "    return x\n",
    "\n",
    "def plot_schedule(schedule: Dict[int, Tuple[int, int, int]], critical_path=[]) -> None:\n",
    "        colors_by_proc = defaultdict(lambda:\n",
    "            ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'])\n",
    "        for id, (start, end, proc) in schedule.items():\n",
    "            # cycle through the colors for this processor\n",
    "            color = cycle(colors_by_proc[proc])\n",
    "            colors_by_proc[proc].append(color)\n",
    "            \n",
    "            # handle critical path nodes\n",
    "            if id in critical_path:\n",
    "                critical_kwargs = {\n",
    "                    'edgecolor': 'red',\n",
    "                    'lw': 2,\n",
    "                    'zorder': 100,\n",
    "                }\n",
    "            else:\n",
    "                critical_kwargs = {}\n",
    "            \n",
    "            # blot the bar and text\n",
    "            plt.broken_barh([(start, end-start)],\n",
    "                            (proc-.4, .8),\n",
    "                            facecolors=color,\n",
    "                            **critical_kwargs)\n",
    "            plt.annotate(str(id),\n",
    "                         xy=((start+end)/2, proc),\n",
    "                         ha='center',\n",
    "                         va='center',\n",
    "                         zorder=101)\n",
    "        plt.yticks(list(colors_by_proc.keys()), [f'Proc {proc}' for proc in colors_by_proc.keys()])\n",
    "        plt.tight_layout()\n",
    "\n",
    "print(schedule)\n",
    "plot_schedule(schedule)\n",
    "plt.savefig('./data/schedule')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18043"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2sbl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e016cbfee4a4a9f8ad68d1216e5f03d3845a8636147ff93c078e6684dcfe1d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
