{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/smallRandom.json\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import bisect\n",
    "\n",
    "from config import filename\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def n2letter(n):\n",
    "    '''0 to 'a', 1 to 'b', ... '''\n",
    "    return chr(96+n)\n",
    "\n",
    "def string2duration(string):\n",
    "    ''' \"01:50:19.3177493\" to duration in seconds'''\n",
    "    return 3600*int(string[:2]) + 60*int(string[3:5]) + int(string[6:8])  #Duration is int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Number of tasks: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'Data': 2843, 'Dependencies': []},\n",
       " 2: {'Data': 3656, 'Dependencies': [1]},\n",
       " 3: {'Data': 2741, 'Dependencies': [1]},\n",
       " 4: {'Data': 4166, 'Dependencies': [1]},\n",
       " 5: {'Data': 5065, 'Dependencies': [2]},\n",
       " 6: {'Data': 5116, 'Dependencies': [4]},\n",
       " 7: {'Data': 3878, 'Dependencies': [2]},\n",
       " 8: {'Data': 3596, 'Dependencies': [5]},\n",
       " 9: {'Data': 5252, 'Dependencies': [7]},\n",
       " 10: {'Data': 2883, 'Dependencies': [8]}}"
      ]
     },
     "execution_count": 1151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(path):\n",
    "    global task_count\n",
    "    global tasks\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    nodes = data['nodes']\n",
    "    tasks = dict()\n",
    "    for task_str, info in nodes.items():\n",
    "        task = int(task_str)\n",
    "        tasks[task] = {'Data' : string2duration(info['Data']), 'Dependencies' : info['Dependencies']}\n",
    "    task_count = len(tasks)\n",
    "    print(\"Data loaded successfully. Number of tasks: \" + str(task_count))\n",
    "\n",
    "n_cores = 2\n",
    "read_data(filename)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [2, 3, 4], 2: [5, 7], 3: [], 4: [6], 5: [8], 6: [], 7: [9], 8: [10], 9: [], 10: []}\n",
      "{1: [], 2: [1], 3: [1], 4: [1], 5: [2], 6: [4], 7: [2], 8: [5], 9: [7], 10: [8]}\n"
     ]
    }
   ],
   "source": [
    "#Tasks to child tasks / Tasks to parents / Task is terminal / Task is inital\n",
    "task2childs = {task : list() for task in tasks}\n",
    "task2parents = {task : list() for task in tasks}\n",
    "for task, info in tasks.items():\n",
    "    #Add childs\n",
    "    list_task_parents = info['Dependencies']\n",
    "    for task_parent in list_task_parents:\n",
    "        task2childs[task_parent].append(task)\n",
    "    #Add parents\n",
    "    task2parents[task] = tasks[task]['Dependencies']\n",
    "    \n",
    "def task_is_terminal(task: int):\n",
    "    return len(task2childs[task]) == 0\n",
    "def task_is_inital(task: int):\n",
    "    return len(task2parents[task]) == 0\n",
    "\n",
    "print(task2childs)\n",
    "print(task2parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 2883,\n",
       " 8: 6479,\n",
       " 5: 11544,\n",
       " 9: 5252,\n",
       " 7: 9130,\n",
       " 2: 15200,\n",
       " 3: 2741,\n",
       " 6: 5116,\n",
       " 4: 9282,\n",
       " 1: 18043}"
      ]
     },
     "execution_count": 1153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2sbl = {}\n",
    "\n",
    "def save_static_bottom_level(task : int):\n",
    "    task_duration = tasks[task][\"Data\"]\n",
    "    if task_is_terminal(task):\n",
    "        sbl = task_duration\n",
    "    else:\n",
    "        list_sbl_child = list()\n",
    "        for task_child in task2childs[task]:\n",
    "            if task_child in task2sbl:\n",
    "                sbl_child = task2sbl[task_child]\n",
    "            else:\n",
    "                sbl_child = save_static_bottom_level(task_child)\n",
    "            list_sbl_child.append(sbl_child)\n",
    "        sbl = max(list_sbl_child) + task_duration\n",
    "                \n",
    "    task2sbl[task] = sbl\n",
    "    return sbl\n",
    "\n",
    "for task in tasks:\n",
    "    if task_is_inital(task):\n",
    "        save_static_bottom_level(task)\n",
    "        \n",
    "task2sbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tasks = tasks\n",
    "        self.tasks_to_sbl = task2sbl\n",
    "        self.tasks_to_parent = task2parents\n",
    "        self.tasks_to_child = task2childs\n",
    "        self.n_cores = 2\n",
    "        self.nodes = list()\n",
    "\n",
    "graph = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    graph = graph\n",
    "    \n",
    "    def __init__(self, parent = None, task_to_add = None, core_where_to_add = None, time_task_start = None):\n",
    "        '''Create a Node object ie a partial scheduling\n",
    "        parent = parent Node, None if root\n",
    "        task_to_add : task added to the partial schedule\n",
    "        core_where_to_add : core where to do task\n",
    "        time_task_start : instant where the core will start computing the task\n",
    "        '''        \n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.tasks_done_time = dict()\n",
    "            self.cores = {core_n : {\"task\" : -1, \"task_end_time\" : 0} for core_n in range(n_cores)}\n",
    "            \n",
    "            self.g = 0\n",
    "            self.f = self.h()\n",
    "                   \n",
    "            self.hist = ''  \n",
    "            self.schedule = dict()\n",
    "            \n",
    "        else:\n",
    "            task_end_time = time_task_start + self.graph.tasks[task_to_add]['Data']\n",
    "            \n",
    "            self.parent = parent\n",
    "            self.tasks_done_time = parent.tasks_done_time.copy()\n",
    "            self.tasks_done_time[task_to_add] = task_end_time\n",
    "\n",
    "            self.cores = parent.cores.copy()\n",
    "            self.cores[core_where_to_add] = {\"task\" : task_to_add, \"task_end_time\" : task_end_time}\n",
    "                \n",
    "            self.g = self.compute_g()\n",
    "            self.f = max(self.g + self.h(), parent.f)\n",
    "            \n",
    "            \n",
    "            self.schedule = parent.schedule.copy()\n",
    "            self.schedule[task_to_add] = (time_task_start, task_end_time, core_where_to_add)\n",
    "            self.hist = parent.hist + f\"|Task {task_to_add} start at time {time_task_start} on core {core_where_to_add} \"\n",
    "                 \n",
    "    def __repr__(self):\n",
    "        string = '[' + ','.join([n2letter(task) for task in self.tasks_done_time]) + ']'\n",
    "        string += ''.join([f\"({core['task']} end at {core['task_end_time']})\" for core in self.cores.values()])\n",
    "        return string\n",
    "            \n",
    "    def is_goal(self):\n",
    "        '''Return whether a node is a full schedule'''\n",
    "        return len(self.tasks_done_time) == task_count\n",
    "    \n",
    "    def successors(self):                     \n",
    "        '''Create and return list of child node of self'''\n",
    "        childs = list()\n",
    "        \n",
    "        #On regarde toutes les tâches qu'on va tenter de rajouter\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            \n",
    "            #On passe les taches déjà ajoutées\n",
    "            if task in self.tasks_done_time: \n",
    "                continue\n",
    "            \n",
    "            #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]): \n",
    "                continue\n",
    "            \n",
    "            #On calcul le temps ou toutes les dépendances de task seront terminés par les coeurs   \n",
    "            time_all_tasks_done = max([0] + [self.tasks_done_time[task_required] for task_required in info['Dependencies']])\n",
    "                                         \n",
    "            for core_n, core in self.cores.items():\n",
    "                #On ne commence à faire la task que lorsque toutes les dépendances sont calculées et que le core est disponible.\n",
    "                time_core_available = core[\"task_end_time\"]\n",
    "                time_task_start = max(time_all_tasks_done, time_core_available)\n",
    "                \n",
    "                child = Node(parent = self, task_to_add=task, core_where_to_add=core_n, time_task_start=time_task_start)    \n",
    "                childs.append(child)\n",
    "                \n",
    "        return sorted(childs, key = lambda node: node.f)\n",
    "        \n",
    "    def cost(self, child_node):\n",
    "        '''Return the cost of going from self to child_node, a child node of self\n",
    "        '''\n",
    "        res = child_node.g - self.g\n",
    "        if res < 0:\n",
    "            raise Exception(\"Cost difference is negative\")\n",
    "        return res\n",
    "    \n",
    "    def h(self):\n",
    "        '''Estimated remaining time of the node-schedule for reaching a terminal node. Must understimate true value.\n",
    "        '''\n",
    "        successor_tasks = list()\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            if task in self.tasks_done_time: #On passe les taches déjà ajoutées\n",
    "                continue\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]):   #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "                continue\n",
    "            successor_tasks.append(task)\n",
    "        if len(successor_tasks) == 0:\n",
    "            return 0\n",
    "        return max([self.graph.tasks_to_sbl[task] for task in successor_tasks])\n",
    "        \n",
    "    \n",
    "    #Node-schedule method\n",
    "    def __lt__(self, node):\n",
    "        return self.f < node.f\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return int(self.f)\n",
    "        \n",
    "    def __eq__(self, node):\n",
    "        '''Return whether a node is equal to another. Two nodes are considered equal if they have completed the same tasks and if all their cores stop working at same time.\n",
    "        '''\n",
    "        if self.g != node.g:\n",
    "            return False       \n",
    "        if self.tasks_done_time != node.tasks_done_time:\n",
    "            return False\n",
    "        # if set(self.cores.values()) != set(node.cores.values()):\n",
    "        #     return False\n",
    "        return self.set_of_core() == node.set_of_core()\n",
    "        \n",
    "    def set_of_core(self):\n",
    "        return set([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "    def compute_g(self):\n",
    "        return max([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "# r = Node()\n",
    "# x,y = r.successors()\n",
    "# a,b,c,d,e,f, *_ = x.successors()[0].successors()\n",
    "# g, h, i, j, k, l, *_ = y.successors()[0].successors()\n",
    "\n",
    "# #Test successors\n",
    "# print(a, b, c, d, e, f, sep = '\\n')\n",
    "# print()\n",
    "# print(g, h, i, j, k, l, sep = '\\n')\n",
    "# print()\n",
    "\n",
    "# #Test __eq__\n",
    "# for i in (g, h, i, j, k, l):\n",
    "#     for j in (a, b, c, d, e, f):\n",
    "#         if i == j:\n",
    "#             print(i, j)\n",
    "\n",
    "# #Test cost\n",
    "# x.cost(a)\n",
    "\n",
    "# #Test h\n",
    "# print(r.h())\n",
    "# print(x.h())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import queue\n",
    "import random as rd\n",
    "\n",
    "class A_star():\n",
    "    def __init__(self, root, graph):\n",
    "        self.root = root\n",
    "        self.graph = graph\n",
    "\n",
    "    def find_best_path(self, max_time = float('inf')):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        OPEN_QUEUE = queue.PriorityQueue()\n",
    "        OPEN_QUEUE.put(self.root)       #Open queue, pile of most urgent node to be evaluated\n",
    "        OPEN_DICT = {self.root: None}   #Open set, more efficient way to compute if a node is in the open list\n",
    "        CLOSED_DICT = dict()            #Closed list, list of already explored node\n",
    "        \n",
    "        while not OPEN_QUEUE.empty():\n",
    "            if time.time() - t0 > max_time:\n",
    "                print('Time out')\n",
    "                return\n",
    "\n",
    "            current = OPEN_QUEUE.get()\n",
    "            del OPEN_DICT[current]\n",
    "            CLOSED_DICT[current] = None\n",
    "            if current.is_goal():   #If we reach a final node, it is the optimal solution and we return it\n",
    "                return current\n",
    "\n",
    "            for child in current.successors():\n",
    "\n",
    "                if child in CLOSED_DICT:    #We pass the node already visited\n",
    "                    continue\n",
    "                    \n",
    "                if child in OPEN_DICT:      #We pass the node already waiting to be visited (note: in A* general, we need to recompute child.g and child.parent here, but for us child.g only depends on child (not on parent))\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    # child.g = current.g + current.cost(child)     #General method. In our case, node.g does not depend on the path and the parent node\n",
    "                    OPEN_QUEUE.put(child)\n",
    "                    OPEN_DICT[child] = None\n",
    "                    \n",
    "        raise Exception(\"No path from root to a terminal node\")\n",
    "    \n",
    "# A_star(root = Node(), graph=graph).find_best_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a,b,d,e,g,h,i,f,c,j](10 end at 22440)(6 end at 20276)\n",
      "         153711 function calls in 0.079 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    47747    0.012    0.000    0.016    0.000 <ipython-input-1155-4caa7eb1f2cf>:107(__eq__)\n",
      "        1    0.011    0.011    0.079    0.079 <ipython-input-1156-f6210091f37a>:10(find_best_path)\n",
      "     2180    0.009    0.000    0.014    0.000 <ipython-input-1155-4caa7eb1f2cf>:85(h)\n",
      "     2180    0.008    0.000    0.030    0.000 <ipython-input-1155-4caa7eb1f2cf>:4(__init__)\n",
      "      364    0.006    0.000    0.038    0.000 <ipython-input-1155-4caa7eb1f2cf>:49(successors)\n",
      "     1391    0.002    0.000    0.008    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:122(put)\n",
      "     2910    0.002    0.000    0.004    0.000 <ipython-input-1155-4caa7eb1f2cf>:118(set_of_core)\n",
      "     5090    0.002    0.000    0.002    0.000 {method 'values' of 'dict' objects}\n",
      "     6540    0.002    0.000    0.002    0.000 {method 'copy' of 'dict' objects}\n",
      "     9806    0.002    0.000    0.002    0.000 {built-in method builtins.max}\n",
      "     2180    0.002    0.000    0.005    0.000 <ipython-input-1155-4caa7eb1f2cf>:121(compute_g)\n",
      "     6457    0.002    0.000    0.002    0.000 <ipython-input-1155-4caa7eb1f2cf>:101(__lt__)\n",
      "     1756    0.001    0.000    0.002    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:351(notify)\n",
      "     6452    0.001    0.000    0.001    0.000 <ipython-input-1155-4caa7eb1f2cf>:104(__hash__)\n",
      "     6926    0.001    0.000    0.001    0.000 <ipython-input-1155-4caa7eb1f2cf>:92(<listcomp>)\n",
      "     8389    0.001    0.000    0.001    0.000 {built-in method builtins.all}\n",
      "     1391    0.001    0.000    0.002    0.000 {built-in method _heapq.heappush}\n",
      "     2910    0.001    0.000    0.001    0.000 <ipython-input-1155-4caa7eb1f2cf>:119(<listcomp>)\n",
      "      365    0.001    0.000    0.004    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:154(get)\n",
      "     2176    0.001    0.000    0.001    0.000 <ipython-input-1155-4caa7eb1f2cf>:97(<listcomp>)\n",
      "     7458    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "      365    0.001    0.000    0.002    0.000 {built-in method _heapq.heappop}\n",
      "     2180    0.001    0.000    0.001    0.000 <ipython-input-1155-4caa7eb1f2cf>:122(<listcomp>)\n",
      "     3634    0.001    0.000    0.001    0.000 {method 'items' of 'dict' objects}\n",
      "      364    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}\n",
      "     1756    0.001    0.000    0.001    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:271(_is_owned)\n",
      "     1756    0.001    0.000    0.001    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:256(__enter__)\n",
      "     1756    0.001    0.000    0.001    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:259(__exit__)\n",
      "     1391    0.000    0.000    0.002    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:235(_put)\n",
      "     1756    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "     3275    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "      365    0.000    0.000    0.001    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:97(empty)\n",
      "     1090    0.000    0.000    0.000    0.000 <ipython-input-1155-4caa7eb1f2cf>:65(<listcomp>)\n",
      "     1756    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "     1463    0.000    0.000    0.000    0.000 <ipython-input-1155-4caa7eb1f2cf>:61(<listcomp>)\n",
      "     2121    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "     2180    0.000    0.000    0.000    0.000 <ipython-input-1155-4caa7eb1f2cf>:75(<lambda>)\n",
      "      730    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:232(_qsize)\n",
      "      365    0.000    0.000    0.000    0.000 <ipython-input-1155-4caa7eb1f2cf>:45(is_goal)\n",
      "      365    0.000    0.000    0.002    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:238(_get)\n",
      "      366    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:34(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:228(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\cProfile.py:117(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:229(_init)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x2110a4e19a0>"
      ]
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "root = Node()\n",
    "a_star = A_star(root = root, graph=graph)\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    final_node = a_star.find_best_path(max_time=10)\n",
    "\n",
    "print(final_node)\n",
    "stats = pstats.Stats(pr)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(filename='profiling.prof')\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (0, 2843, 0), 2: (2843, 6499, 0), 4: (2843, 7009, 1), 5: (6499, 11564, 0), 7: (7009, 10887, 1), 8: (11564, 15160, 1), 9: (11564, 16816, 0), 6: (15160, 20276, 1), 3: (16816, 19557, 0), 10: (19557, 22440, 0)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import cycle\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "schedule = final_node.schedule\n",
    "\n",
    "def cycle(lst: list[str]) -> str:\n",
    "    x = lst.pop(0)\n",
    "    lst.append(x)\n",
    "    return x\n",
    "\n",
    "def plot_schedule(schedule: Dict[int, Tuple[int, int, int]], critical_path=[]) -> None:\n",
    "        colors_by_proc = defaultdict(lambda:\n",
    "            ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'])\n",
    "        for id, (start, end, proc) in schedule.items():\n",
    "            # cycle through the colors for this processor\n",
    "            color = cycle(colors_by_proc[proc])\n",
    "            colors_by_proc[proc].append(color)\n",
    "            \n",
    "            # handle critical path nodes\n",
    "            if id in critical_path:\n",
    "                critical_kwargs = {\n",
    "                    'edgecolor': 'red',\n",
    "                    'lw': 2,\n",
    "                    'zorder': 100,\n",
    "                }\n",
    "            else:\n",
    "                critical_kwargs = {}\n",
    "            \n",
    "            # blot the bar and text\n",
    "            plt.broken_barh([(start, end-start)],\n",
    "                            (proc-.4, .8),\n",
    "                            facecolors=color,\n",
    "                            **critical_kwargs)\n",
    "            plt.annotate(str(id),\n",
    "                         xy=((start+end)/2, proc),\n",
    "                         ha='center',\n",
    "                         va='center',\n",
    "                         zorder=101)\n",
    "        plt.yticks(list(colors_by_proc.keys()), [f'Proc {proc}' for proc in colors_by_proc.keys()])\n",
    "        plt.tight_layout()\n",
    "\n",
    "print(schedule)\n",
    "plot_schedule(schedule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1180]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_schedule\u001b[39m(\u001b[39mself\u001b[39m, schedule: Dict[\u001b[39mint\u001b[39m, Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]], critical_path\u001b[39m=\u001b[39m[]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m         colors_by_proc \u001b[39m=\u001b[39m defaultdict(\u001b[39mlambda\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m             [\u001b[39m'\u001b[39m\u001b[39mtab:blue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtab:orange\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtab:green\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtab:purple\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtab:brown\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtab:pink\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtab:gray\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtab:olive\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtab:cyan\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m         \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, (start, end, proc) \u001b[39min\u001b[39;00m schedule\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m             \u001b[39m# cycle through the colors for this processor\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_schedule(self, schedule: dict[int, tuple[int, int, int]], critical_path=[]) -> None:\n",
    "        colors_by_proc = defaultdict(lambda:\n",
    "            ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'])\n",
    "        for id, (start, end, proc) in schedule.items():\n",
    "            # cycle through the colors for this processor\n",
    "            color = cycle(colors_by_proc[proc])\n",
    "            colors_by_proc[proc].append(color)\n",
    "            \n",
    "            # handle critical path nodes\n",
    "            if id in critical_path:\n",
    "                critical_kwargs = {\n",
    "                    'edgecolor': 'red',\n",
    "                    'lw': 2,\n",
    "                    'zorder': 100,\n",
    "                }\n",
    "            else:\n",
    "                critical_kwargs = {}\n",
    "            \n",
    "            # blot the bar and text\n",
    "            plt.broken_barh([(start, end-start)],\n",
    "                            (proc-.4, .8),\n",
    "                            facecolors=color,\n",
    "                            **critical_kwargs)\n",
    "            plt.annotate(str(id),\n",
    "                         xy=((start+end)/2, proc),\n",
    "                         ha='center',\n",
    "                         va='center',\n",
    "                         zorder=101)\n",
    "        plt.yticks(list(colors_by_proc.keys()), [f'Proc {proc}' for proc in colors_by_proc.keys()])\n",
    "        plt.tight_layout()\n",
    "\n",
    "plot_schedule(schedule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21255"
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2843 + 3878 + 5252 + 4166 + 5116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-471"
      ]
     },
     "execution_count": 1109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20784 - 21255\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e016cbfee4a4a9f8ad68d1216e5f03d3845a8636147ff93c078e6684dcfe1d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
