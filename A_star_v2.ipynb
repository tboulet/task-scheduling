{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/smallRandom.json\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import bisect\n",
    "\n",
    "from config import filename, n_cores\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def n2letter(n):\n",
    "    '''0 to 'a', 1 to 'b', ... '''\n",
    "    return chr(96+n)\n",
    "\n",
    "def string2duration(string):\n",
    "    ''' \"01:50:19.3177493\" to duration in seconds'''\n",
    "    return 3600*int(string[:2]) + 60*int(string[3:5]) + int(string[6:8])  #Duration is int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Number of tasks: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'Data': 2843, 'Dependencies': []},\n",
       " 2: {'Data': 3656, 'Dependencies': [1]},\n",
       " 3: {'Data': 2741, 'Dependencies': [1]},\n",
       " 4: {'Data': 4166, 'Dependencies': [1]},\n",
       " 5: {'Data': 5065, 'Dependencies': [2]},\n",
       " 6: {'Data': 5116, 'Dependencies': [4]},\n",
       " 7: {'Data': 3878, 'Dependencies': [2]},\n",
       " 8: {'Data': 3596, 'Dependencies': [5]},\n",
       " 9: {'Data': 5252, 'Dependencies': [7]},\n",
       " 10: {'Data': 2883, 'Dependencies': [8]}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(path):\n",
    "    global task_count\n",
    "    global tasks\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    nodes = data['nodes']\n",
    "    tasks = dict()\n",
    "    for task_str, info in nodes.items():\n",
    "        task = int(task_str)\n",
    "        tasks[task] = {'Data' : string2duration(info['Data']), 'Dependencies' : info['Dependencies']}\n",
    "    task_count = len(tasks)\n",
    "    print(\"Data loaded successfully. Number of tasks: \" + str(task_count))\n",
    "\n",
    "read_data(filename)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [2, 3, 4], 2: [5, 7], 3: [], 4: [6], 5: [8], 6: [], 7: [9], 8: [10], 9: [], 10: []}\n",
      "{1: [], 2: [1], 3: [1], 4: [1], 5: [2], 6: [4], 7: [2], 8: [5], 9: [7], 10: [8]}\n"
     ]
    }
   ],
   "source": [
    "#Tasks to child tasks / Tasks to parents / Task is terminal / Task is inital\n",
    "task2childs = {task : list() for task in tasks}\n",
    "task2parents = {task : list() for task in tasks}\n",
    "for task, info in tasks.items():\n",
    "    #Add childs\n",
    "    list_task_parents = info['Dependencies']\n",
    "    for task_parent in list_task_parents:\n",
    "        task2childs[task_parent].append(task)\n",
    "    #Add parents\n",
    "    task2parents[task] = tasks[task]['Dependencies']\n",
    "    \n",
    "def task_is_terminal(task: int):\n",
    "    return len(task2childs[task]) == 0\n",
    "def task_is_inital(task: int):\n",
    "    return len(task2parents[task]) == 0\n",
    "\n",
    "print(task2childs)\n",
    "print(task2parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 2883,\n",
       " 8: 6479,\n",
       " 5: 11544,\n",
       " 9: 5252,\n",
       " 7: 9130,\n",
       " 2: 15200,\n",
       " 3: 2741,\n",
       " 6: 5116,\n",
       " 4: 9282,\n",
       " 1: 18043}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2sbl = {}\n",
    "\n",
    "def save_static_bottom_level(task : int):\n",
    "    task_duration = tasks[task][\"Data\"]\n",
    "    if task_is_terminal(task):\n",
    "        sbl = task_duration\n",
    "    else:\n",
    "        list_sbl_child = list()\n",
    "        for task_child in task2childs[task]:\n",
    "            if task_child in task2sbl:\n",
    "                sbl_child = task2sbl[task_child]\n",
    "            else:\n",
    "                sbl_child = save_static_bottom_level(task_child)\n",
    "            list_sbl_child.append(sbl_child)\n",
    "        sbl = max(list_sbl_child) + task_duration\n",
    "                \n",
    "    task2sbl[task] = sbl\n",
    "    return sbl\n",
    "\n",
    "for task in tasks:\n",
    "    if task_is_inital(task):\n",
    "        save_static_bottom_level(task)\n",
    "        \n",
    "task2sbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tasks = tasks\n",
    "        self.tasks_to_sbl = task2sbl\n",
    "        self.tasks_to_parent = task2parents\n",
    "        self.tasks_to_child = task2childs\n",
    "        self.n_cores = 2\n",
    "        self.nodes = list()\n",
    "\n",
    "graph = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    graph = graph\n",
    "    \n",
    "    def __init__(self, parent = None, task_to_add = None, core_where_to_add = None, time_task_start = None):\n",
    "        '''Create a Node object ie a partial scheduling\n",
    "        parent = parent Node, None if root\n",
    "        task_to_add : task added to the partial schedule\n",
    "        core_where_to_add : core where to do task\n",
    "        time_task_start : instant where the core will start computing the task\n",
    "        '''        \n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.tasks_done_time = dict()\n",
    "            self.cores = {core_n : {\"task\" : -1, \"task_end_time\" : 0} for core_n in range(n_cores)}\n",
    "            \n",
    "            self.g = 0\n",
    "            self.f = self.h()\n",
    "                   \n",
    "            self.hist = ''  \n",
    "            self.schedule = dict()\n",
    "            \n",
    "        else:\n",
    "            task_end_time = time_task_start + self.graph.tasks[task_to_add]['Data']\n",
    "            \n",
    "            self.parent = parent\n",
    "            self.tasks_done_time = parent.tasks_done_time.copy()\n",
    "            self.tasks_done_time[task_to_add] = task_end_time\n",
    "\n",
    "            self.cores = parent.cores.copy()\n",
    "            self.cores[core_where_to_add] = {\"task\" : task_to_add, \"task_end_time\" : task_end_time}\n",
    "                \n",
    "            self.g = self.compute_g()\n",
    "            self.f = max(self.g + self.h(), parent.f)\n",
    "            \n",
    "            \n",
    "            self.schedule = parent.schedule.copy()\n",
    "            self.schedule[task_to_add] = (time_task_start, task_end_time, core_where_to_add)\n",
    "            self.hist = parent.hist + f\"|Task {task_to_add} start at time {time_task_start} on core {core_where_to_add} \"\n",
    "                 \n",
    "    def __repr__(self):\n",
    "        string = '[' + ','.join([n2letter(task) for task in self.tasks_done_time]) + ']'\n",
    "        string += ''.join([f\"({core['task']} end at {core['task_end_time']})\" for core in self.cores.values()])\n",
    "        return string\n",
    "            \n",
    "    def is_goal(self):\n",
    "        '''Return whether a node is a full schedule'''\n",
    "        return len(self.tasks_done_time) == task_count\n",
    "    \n",
    "    def successors(self):                     \n",
    "        '''Create and return list of child node of self'''\n",
    "        childs = list()\n",
    "        \n",
    "        #On regarde toutes les tâches qu'on va tenter de rajouter\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            \n",
    "            #On passe les taches déjà ajoutées\n",
    "            if task in self.tasks_done_time: \n",
    "                continue\n",
    "            \n",
    "            #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]): \n",
    "                continue\n",
    "            \n",
    "            #On calcul le temps ou toutes les dépendances de task seront terminés par les coeurs   \n",
    "            time_all_tasks_done = max([0] + [self.tasks_done_time[task_required] for task_required in info['Dependencies']])\n",
    "                                         \n",
    "            for core_n, core in self.cores.items():\n",
    "                #On ne commence à faire la task que lorsque toutes les dépendances sont calculées et que le core est disponible.\n",
    "                time_core_available = core[\"task_end_time\"]\n",
    "                time_task_start = max(time_all_tasks_done, time_core_available)\n",
    "                \n",
    "                child = Node(parent = self, task_to_add=task, core_where_to_add=core_n, time_task_start=time_task_start)    \n",
    "                childs.append(child)\n",
    "                \n",
    "        return sorted(childs, key = lambda node: node.f)\n",
    "        \n",
    "    def cost(self, child_node):\n",
    "        '''Return the cost of going from self to child_node, a child node of self\n",
    "        '''\n",
    "        res = child_node.g - self.g\n",
    "        if res < 0:\n",
    "            raise Exception(\"Cost difference is negative\")\n",
    "        return res\n",
    "    \n",
    "    def h(self):\n",
    "        '''Estimated remaining time of the node-schedule for reaching a terminal node. Must understimate true value.\n",
    "        '''\n",
    "        successor_tasks = list()\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            if task in self.tasks_done_time: #On passe les taches déjà ajoutées\n",
    "                continue\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]):   #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "                continue\n",
    "            successor_tasks.append(task)\n",
    "        if len(successor_tasks) == 0:\n",
    "            return 0\n",
    "        return max([self.graph.tasks_to_sbl[task] for task in successor_tasks])\n",
    "        \n",
    "    \n",
    "    #Node-schedule method\n",
    "    def __lt__(self, node):\n",
    "        return self.f < node.f\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return int(self.f)\n",
    "        \n",
    "    def __eq__(self, node):\n",
    "        '''Return whether a node is equal to another. Two nodes are considered equal if they have completed the same tasks and if all their cores stop working at same time.\n",
    "        '''\n",
    "        if self.g != node.g:\n",
    "            return False       \n",
    "        if self.tasks_done_time != node.tasks_done_time:\n",
    "            return False\n",
    "        # if set(self.cores.values()) != set(node.cores.values()):\n",
    "        #     return False\n",
    "        return self.set_of_core() == node.set_of_core()\n",
    "        \n",
    "    def set_of_core(self):\n",
    "        return set([(core_n, core[\"task_end_time\"]) for core_n, core in self.cores.items()])\n",
    "    \n",
    "    def compute_g(self):\n",
    "        return max([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "# r = Node()\n",
    "# x,y = r.successors()\n",
    "# a,b,c,d,e,f, *_ = x.successors()[0].successors()\n",
    "# g, h, i, j, k, l, *_ = y.successors()[0].successors()\n",
    "\n",
    "# #Test successors\n",
    "# print(a, b, c, d, e, f, sep = '\\n')\n",
    "# print()\n",
    "# print(g, h, i, j, k, l, sep = '\\n')\n",
    "# print()\n",
    "\n",
    "# #Test __eq__\n",
    "# for i in (g, h, i, j, k, l):\n",
    "#     for j in (a, b, c, d, e, f):\n",
    "#         if i == j:\n",
    "#             print(i, j)\n",
    "\n",
    "# #Test cost\n",
    "# x.cost(a)\n",
    "\n",
    "# #Test h\n",
    "# print(r.h())\n",
    "# print(x.h())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import queue\n",
    "import random as rd\n",
    "\n",
    "class A_star():\n",
    "    def __init__(self, root, graph):\n",
    "        self.root = root\n",
    "        self.graph = graph\n",
    "\n",
    "    def find_best_path(self, max_time = float('inf')):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        OPEN_QUEUE = queue.PriorityQueue()\n",
    "        OPEN_QUEUE.put(self.root)       #Open queue, pile of most urgent node to be evaluated\n",
    "        OPEN_SET = {self.root}   #Open set, more efficient way to compute if a node is in the open list\n",
    "        CLOSED_SET = set()            #Closed list, list of already explored node\n",
    "        \n",
    "        while not OPEN_QUEUE.empty():\n",
    "            if time.time() - t0 > max_time:\n",
    "                print('Time out')\n",
    "                return\n",
    "\n",
    "            current = OPEN_QUEUE.get()\n",
    "            OPEN_SET.remove(current)\n",
    "            CLOSED_SET.add(current)\n",
    "            if current.is_goal():   #If we reach a final node, it is the optimal solution and we return it\n",
    "                return current\n",
    "\n",
    "            for child in current.successors():\n",
    "\n",
    "                if child in CLOSED_SET:    #We pass the node already visited\n",
    "                    continue\n",
    "                    \n",
    "                if child in OPEN_SET:      #We pass the node already waiting to be visited (note: in A* general, we need to recompute child.g and child.parent here, but for us child.g only depends on child (not on parent))\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    # child.g = current.g + current.cost(child)     #General method. In our case, node.g does not depend on the path and the parent node\n",
    "                    OPEN_QUEUE.put(child)\n",
    "                    OPEN_SET.add(child)\n",
    "                    \n",
    "        raise Exception(\"No path from root to a terminal node\")\n",
    "    \n",
    "# A_star(root = Node(), graph=graph).find_best_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a,b,c,d,e,g,f,h,i,j](6 end at 12125)(9 end at 15629)(4 end at 7009)(10 end at 18043)(7 end at 10377)\n",
      "         30171664 function calls in 16.577 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "  9570857    5.549    0.000   14.687    0.000 <ipython-input-126-3705135e2650>:107(__eq__)\n",
      "  6713966    5.262    0.000    9.139    0.000 <ipython-input-126-3705135e2650>:118(set_of_core)\n",
      "  6713966    3.332    0.000    3.332    0.000 <ipython-input-126-3705135e2650>:119(<listcomp>)\n",
      "        1    0.841    0.841   16.577   16.577 <ipython-input-127-6290cbdc01d0>:10(find_best_path)\n",
      "     8839    0.704    0.000    7.427    0.001 {method 'add' of 'set' objects}\n",
      "  6726145    0.546    0.000    0.546    0.000 {method 'items' of 'dict' objects}\n",
      "     9650    0.049    0.000    0.076    0.000 <ipython-input-126-3705135e2650>:85(h)\n",
      "     8240    0.037    0.000    0.116    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:122(put)\n",
      "     9650    0.034    0.000    0.138    0.000 <ipython-input-126-3705135e2650>:4(__init__)\n",
      "      600    0.030    0.000    0.325    0.001 {method 'remove' of 'set' objects}\n",
      "     8840    0.023    0.000    0.033    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:351(notify)\n",
      "      599    0.021    0.000    0.169    0.000 <ipython-input-126-3705135e2650>:49(successors)\n",
      "     8240    0.012    0.000    0.018    0.000 {built-in method _heapq.heappush}\n",
      "     9650    0.011    0.000    0.019    0.000 <ipython-input-126-3705135e2650>:121(compute_g)\n",
      "    28569    0.011    0.000    0.011    0.000 <ipython-input-126-3705135e2650>:104(__hash__)\n",
      "    21380    0.010    0.000    0.010    0.000 <ipython-input-126-3705135e2650>:101(__lt__)\n",
      "    40490    0.009    0.000    0.009    0.000 {built-in method builtins.max}\n",
      "    49180    0.009    0.000    0.009    0.000 <ipython-input-126-3705135e2650>:92(<listcomp>)\n",
      "     8840    0.008    0.000    0.016    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:256(__enter__)\n",
      "     8840    0.007    0.000    0.007    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "    28950    0.007    0.000    0.007    0.000 {method 'copy' of 'dict' objects}\n",
      "    52752    0.007    0.000    0.007    0.000 {built-in method builtins.all}\n",
      "     8840    0.006    0.000    0.009    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:259(__exit__)\n",
      "     8240    0.006    0.000    0.024    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:235(_put)\n",
      "     8840    0.006    0.000    0.010    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:271(_is_owned)\n",
      "     9650    0.004    0.000    0.004    0.000 <ipython-input-126-3705135e2650>:122(<listcomp>)\n",
      "     8840    0.004    0.000    0.004    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "     9610    0.004    0.000    0.004    0.000 <ipython-input-126-3705135e2650>:97(<listcomp>)\n",
      "    38300    0.004    0.000    0.004    0.000 {method 'append' of 'list' objects}\n",
      "      599    0.003    0.000    0.004    0.000 {built-in method builtins.sorted}\n",
      "      600    0.003    0.000    0.012    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:154(get)\n",
      "     9440    0.003    0.000    0.003    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "      600    0.003    0.000    0.006    0.000 {built-in method _heapq.heappop}\n",
      "      600    0.002    0.000    0.003    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:97(empty)\n",
      "    11450    0.002    0.000    0.002    0.000 {built-in method builtins.len}\n",
      "     9650    0.001    0.000    0.001    0.000 {method 'values' of 'dict' objects}\n",
      "     9650    0.001    0.000    0.001    0.000 <ipython-input-126-3705135e2650>:75(<lambda>)\n",
      "      600    0.001    0.000    0.001    0.000 <ipython-input-126-3705135e2650>:45(is_goal)\n",
      "     3572    0.001    0.000    0.001    0.000 <ipython-input-126-3705135e2650>:61(<listcomp>)\n",
      "      601    0.001    0.000    0.001    0.000 {built-in method time.time}\n",
      "     1200    0.001    0.000    0.001    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:232(_qsize)\n",
      "     1930    0.001    0.000    0.001    0.000 <ipython-input-126-3705135e2650>:65(<listcomp>)\n",
      "      600    0.000    0.000    0.007    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:238(_get)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:34(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:228(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\cProfile.py:117(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\queue.py:229(_init)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x272eb5cc2e0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "root = Node()\n",
    "a_star = A_star(root = root, graph=graph)\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    final_node = a_star.find_best_path()\n",
    "\n",
    "print(final_node)\n",
    "stats = pstats.Stats(pr)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(filename='profiling.prof')\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: (0, 2843, 1), 2: (2843, 6499, 3), 3: (2843, 5584, 0), 4: (2843, 7009, 2), 5: (6499, 11564, 3), 7: (6499, 10377, 4), 6: (7009, 12125, 0), 8: (11564, 15160, 3), 9: (10377, 15629, 1), 10: (15160, 18043, 3)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import cycle\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "schedule = final_node.schedule\n",
    "\n",
    "def cycle(lst: list[str]) -> str:\n",
    "    x = lst.pop(0)\n",
    "    lst.append(x)\n",
    "    return x\n",
    "\n",
    "def plot_schedule(schedule: Dict[int, Tuple[int, int, int]], critical_path=[]) -> None:\n",
    "        colors_by_proc = defaultdict(lambda:\n",
    "            ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'])\n",
    "        for id, (start, end, proc) in schedule.items():\n",
    "            # cycle through the colors for this processor\n",
    "            color = cycle(colors_by_proc[proc])\n",
    "            colors_by_proc[proc].append(color)\n",
    "            \n",
    "            # handle critical path nodes\n",
    "            if id in critical_path:\n",
    "                critical_kwargs = {\n",
    "                    'edgecolor': 'red',\n",
    "                    'lw': 2,\n",
    "                    'zorder': 100,\n",
    "                }\n",
    "            else:\n",
    "                critical_kwargs = {}\n",
    "            \n",
    "            # blot the bar and text\n",
    "            plt.broken_barh([(start, end-start)],\n",
    "                            (proc-.4, .8),\n",
    "                            facecolors=color,\n",
    "                            **critical_kwargs)\n",
    "            plt.annotate(str(id),\n",
    "                         xy=((start+end)/2, proc),\n",
    "                         ha='center',\n",
    "                         va='center',\n",
    "                         zorder=101)\n",
    "        plt.yticks(list(colors_by_proc.keys()), [f'Proc {proc}' for proc in colors_by_proc.keys()])\n",
    "        plt.tight_layout()\n",
    "\n",
    "print(schedule)\n",
    "plot_schedule(schedule)\n",
    "plt.savefig('./data/schedule')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e016cbfee4a4a9f8ad68d1216e5f03d3845a8636147ff93c078e6684dcfe1d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
