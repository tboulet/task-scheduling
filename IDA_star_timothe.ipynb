{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/smallRandom.json\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import bisect\n",
    "\n",
    "from config import filename, n_cores\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def n2letter(n):\n",
    "    '''0 to 'a', 1 to 'b', ... '''\n",
    "    return chr(96+n)\n",
    "\n",
    "def string2duration(string):\n",
    "    ''' \"01:50:19.3177493\" to duration in seconds'''\n",
    "    return 3600*int(string[:2]) + 60*int(string[3:5]) + int(string[6:8])  #Duration is int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Number of tasks: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'Data': 2843, 'Dependencies': []},\n",
       " 2: {'Data': 3656, 'Dependencies': [1]},\n",
       " 3: {'Data': 2741, 'Dependencies': [1]},\n",
       " 4: {'Data': 4166, 'Dependencies': [1]},\n",
       " 5: {'Data': 5065, 'Dependencies': [2]},\n",
       " 6: {'Data': 5116, 'Dependencies': [4]},\n",
       " 7: {'Data': 3878, 'Dependencies': [2]},\n",
       " 8: {'Data': 3596, 'Dependencies': [5]},\n",
       " 9: {'Data': 5252, 'Dependencies': [7]},\n",
       " 10: {'Data': 2883, 'Dependencies': [8]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(path):\n",
    "    global task_count\n",
    "    global tasks\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    nodes = data['nodes']\n",
    "    tasks = dict()\n",
    "    for task_str, info in nodes.items():\n",
    "        task = int(task_str)\n",
    "        tasks[task] = {'Data' : string2duration(info['Data']), 'Dependencies' : info['Dependencies']}\n",
    "    task_count = len(tasks)\n",
    "    print(\"Data loaded successfully. Number of tasks: \" + str(task_count))\n",
    "\n",
    "read_data(filename)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [2, 3, 4], 2: [5, 7], 3: [], 4: [6], 5: [8], 6: [], 7: [9], 8: [10], 9: [], 10: []}\n",
      "{1: [], 2: [1], 3: [1], 4: [1], 5: [2], 6: [4], 7: [2], 8: [5], 9: [7], 10: [8]}\n"
     ]
    }
   ],
   "source": [
    "#Tasks to child tasks / Tasks to parents / Task is terminal / Task is inital\n",
    "task2childs = {task : list() for task in tasks}\n",
    "task2parents = {task : list() for task in tasks}\n",
    "for task, info in tasks.items():\n",
    "    #Add childs\n",
    "    list_task_parents = info['Dependencies']\n",
    "    for task_parent in list_task_parents:\n",
    "        task2childs[task_parent].append(task)\n",
    "    #Add parents\n",
    "    task2parents[task] = tasks[task]['Dependencies']\n",
    "    \n",
    "def task_is_terminal(task: int):\n",
    "    return len(task2childs[task]) == 0\n",
    "def task_is_inital(task: int):\n",
    "    return len(task2parents[task]) == 0\n",
    "\n",
    "print(task2childs)\n",
    "print(task2parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 2883,\n",
       " 8: 6479,\n",
       " 5: 11544,\n",
       " 9: 5252,\n",
       " 7: 9130,\n",
       " 2: 15200,\n",
       " 3: 2741,\n",
       " 6: 5116,\n",
       " 4: 9282,\n",
       " 1: 18043}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2sbl = {}\n",
    "\n",
    "def save_static_bottom_level(task : int):\n",
    "    task_duration = tasks[task][\"Data\"]\n",
    "    if task_is_terminal(task):\n",
    "        sbl = task_duration\n",
    "    else:\n",
    "        list_sbl_child = list()\n",
    "        for task_child in task2childs[task]:\n",
    "            if task_child in task2sbl:\n",
    "                sbl_child = task2sbl[task_child]\n",
    "            else:\n",
    "                sbl_child = save_static_bottom_level(task_child)\n",
    "            list_sbl_child.append(sbl_child)\n",
    "        sbl = max(list_sbl_child) + task_duration\n",
    "                \n",
    "    task2sbl[task] = sbl\n",
    "    return sbl\n",
    "\n",
    "for task in tasks:\n",
    "    if task_is_inital(task):\n",
    "        save_static_bottom_level(task)\n",
    "        \n",
    "task2sbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tasks = tasks\n",
    "        self.tasks_to_sbl = task2sbl\n",
    "        self.tasks_to_parent = task2parents\n",
    "        self.tasks_to_child = task2childs\n",
    "        self.n_cores = 2\n",
    "        self.nodes = list()\n",
    "\n",
    "graph = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    graph = graph\n",
    "    \n",
    "    def __init__(self, parent = None, task_to_add = None, core_where_to_add = None, time_task_start = None):\n",
    "        '''Create a Node object ie a partial scheduling\n",
    "        parent = parent Node, None if root\n",
    "        task_to_add : task added to the partial schedule\n",
    "        core_where_to_add : core where to do task\n",
    "        time_task_start : instant where the core will start computing the task\n",
    "        '''        \n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.tasks_done_time = dict()\n",
    "            self.cores = {core_n : {\"task\" : -1, \"task_end_time\" : 0} for core_n in range(n_cores)}\n",
    "            \n",
    "            self.g = 0\n",
    "            self.f = self.h()\n",
    "                   \n",
    "            self.hist = ''  \n",
    "            self.schedule = dict()\n",
    "            \n",
    "        else:\n",
    "            task_end_time = time_task_start + self.graph.tasks[task_to_add]['Data']\n",
    "            \n",
    "            self.parent = parent\n",
    "            self.tasks_done_time = parent.tasks_done_time.copy()\n",
    "            self.tasks_done_time[task_to_add] = task_end_time\n",
    "\n",
    "            self.cores = parent.cores.copy()\n",
    "            self.cores[core_where_to_add] = {\"task\" : task_to_add, \"task_end_time\" : task_end_time}\n",
    "                \n",
    "            self.g = max(parent.g, task_end_time)\n",
    "            # self.f = max(self.g + self.h(), parent.f)\n",
    "            self.f = self.g + self.h()\n",
    "            \n",
    "            self.schedule = parent.schedule.copy()\n",
    "            self.schedule[task_to_add] = (time_task_start, task_end_time, core_where_to_add)\n",
    "            self.hist = parent.hist + f\"|Task {task_to_add} start at time {time_task_start} on core {core_where_to_add} \"\n",
    "                 \n",
    "    def __repr__(self):\n",
    "        string = '[' + ','.join([n2letter(task) for task in self.tasks_done_time]) + ']'\n",
    "        string += ''.join([f\"({core['task']} end at {core['task_end_time']})\" for core in self.cores.values()])\n",
    "        return string\n",
    "            \n",
    "    def is_goal(self):\n",
    "        '''Return whether a node is a full schedule'''\n",
    "        return len(self.tasks_done_time) == task_count\n",
    "    \n",
    "    def successors(self):                     \n",
    "        '''Create and return list of child node of self'''\n",
    "        childs = list()\n",
    "        \n",
    "        #On regarde toutes les tâches qu'on va tenter de rajouter\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            \n",
    "            #On passe les taches déjà ajoutées\n",
    "            if task in self.tasks_done_time: \n",
    "                continue\n",
    "            \n",
    "            #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]): \n",
    "                continue\n",
    "            \n",
    "            #On calcul le temps ou toutes les dépendances de task seront terminés par les coeurs   \n",
    "            time_all_tasks_done = max([0] + [self.tasks_done_time[task_required] for task_required in info['Dependencies']])\n",
    "                                         \n",
    "            for core_n, core in self.cores.items():\n",
    "                #On ne commence à faire la task que lorsque toutes les dépendances sont calculées et que le core est disponible.\n",
    "                time_core_available = core[\"task_end_time\"]\n",
    "                time_task_start = max(time_all_tasks_done, time_core_available)\n",
    "                \n",
    "                child = Node(parent = self, task_to_add=task, core_where_to_add=core_n, time_task_start=time_task_start)    \n",
    "                childs.append(child)\n",
    "                \n",
    "        return sorted(childs, key = lambda node: node.f)\n",
    "        \n",
    "    def cost(self, child_node):\n",
    "        '''Return the cost of going from self to child_node, a child node of self\n",
    "        '''\n",
    "        res = child_node.g - self.g\n",
    "        if res < 0:\n",
    "            raise Exception(\"Cost difference is negative\")\n",
    "        return res\n",
    "    \n",
    "    def h(self):\n",
    "        '''Estimated remaining time of the node-schedule for reaching a terminal node. Must understimate true value.\n",
    "        '''\n",
    "        successor_tasks = list()\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            if task in self.tasks_done_time: #On passe les taches déjà ajoutées\n",
    "                continue\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]):   #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "                continue\n",
    "            successor_tasks.append(task)\n",
    "        if len(successor_tasks) == 0:\n",
    "            return 0\n",
    "        return max([self.graph.tasks_to_sbl[task] for task in successor_tasks])\n",
    "        \n",
    "    \n",
    "    #Node-schedule method\n",
    "    def __lt__(self, node):\n",
    "        return self.f < node.f\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return int(self.f)\n",
    "        \n",
    "    def __eq__(self, node):\n",
    "        '''Return whether a node is equal to another. Two nodes are considered equal if they have completed the same tasks and if all their cores stop working at same time.\n",
    "        '''\n",
    "        if self.g != node.g:\n",
    "            return False       \n",
    "        if self.tasks_done_time != node.tasks_done_time:\n",
    "            return False\n",
    "        return self.set_of_core() == node.set_of_core()\n",
    "        \n",
    "    def set_of_core(self):\n",
    "        return set([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "    def compute_g(self):\n",
    "        return max([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "# r = Node()\n",
    "# x,y = r.successors()\n",
    "# a,b,c,d,e,f, *_ = x.successors()\n",
    "# g, h, i, j, k, l, *_ = y.successors()\n",
    "\n",
    "# #Test successors\n",
    "# print(a, b, c, d, e, f, sep = '\\n')\n",
    "# print()\n",
    "# print(g, h, i, j, k, l, sep = '\\n')\n",
    "# print()\n",
    "\n",
    "# #Test __eq__\n",
    "# for i in (g, h, i, j, k, l):\n",
    "#     for j in (a, b, c, d, e, f):\n",
    "#         if i == j:\n",
    "#             print(i, j)\n",
    "\n",
    "# #Test cost\n",
    "# x.cost(a)\n",
    "\n",
    "#Test h\n",
    "# print(r.h())\n",
    "# print(x.h())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import queue\n",
    "import random as rd\n",
    "import sys\n",
    "\n",
    "def rdraise(x = 0.1):\n",
    "    if rd.random() < x:\n",
    "        raise\n",
    "\n",
    "class IDA_star():\n",
    "    def __init__(self, root, graph):\n",
    "        self.root = root\n",
    "        self.graph = graph\n",
    "\n",
    "    def find_best_path(self):\n",
    "        self.solution_found = False\n",
    "        bound = self.root.h()\n",
    "        self.path = [self.root]\n",
    "        while len(self.path) > 0:\n",
    "            found, score = self.search(bound)\n",
    "            if found:\n",
    "                return self.path[-1]\n",
    "            bound = score\n",
    "        raise Exception(\"No path from root to a terminal node\")\n",
    "            \n",
    "    def search(self, bound):\n",
    "        '''Search for the fastest way to a terminal node starting to the last node in the path (ie current node)\n",
    "        bound : f-score maximal for keep searching in a branch. If the f-score of a node is inferior to bound, it means bound < f < f_real so the node is the solution.\n",
    "        return : a tuple (FOUND, F_SCORE)\n",
    "            FOUND : whether we have found the terminal node which is the solution\n",
    "            F_SCORE : the true F_SCORE\n",
    "        '''\n",
    "        #Select current node\n",
    "        node = self.path[-1]\n",
    "        #If the f score exceeds the threshold, we cut down the exploration branch by returning this bad f score.\n",
    "        if node.f > bound:         \n",
    "            return False, node.f\n",
    "        #If we reach the goal, it means f_score <= f_score_any_brothers (because node.successors() is sorted) and f_score <= f_score_any_nodes (by construction) so it is the solution\n",
    "        if node.is_goal():\n",
    "            return True, node.f\n",
    "        #We explore the successors of node in order to return the best node\n",
    "        mini = float('inf')    \n",
    "        successors = node.successors()\n",
    "        for succ in successors:\n",
    "            self.path.append(succ)\n",
    "            found, score = self.search(bound)\n",
    "            #We found the solution so we just return True recursively. The solution is the self.path\n",
    "            if found:\n",
    "                #A terminal node was found but we take its best brother in terms of f score\n",
    "                best_node = sorted(self.path[-2].successors(), key = lambda node : node.g + node.h())[0]\n",
    "                self.path[-1] = best_node\n",
    "                return True, score\n",
    "            if score < mini:\n",
    "                mini = score\n",
    "            self.path.pop()\n",
    "        return False, mini\n",
    "            \n",
    "    \n",
    "fn = IDA_star(root = Node(), graph=graph).find_best_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a,b,c,d,e,g,f,h,i,j](10 end at 18043)(9 end at 15629)(6 end at 12125)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import cycle\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def cycle(lst: list[str]) -> str:\n",
    "    x = lst.pop(0)\n",
    "    lst.append(x)\n",
    "    return x\n",
    "\n",
    "def plot_schedule(node, critical_path=[]) -> None:\n",
    "    schedule = node.schedule\n",
    "    colors_by_proc = defaultdict(lambda:\n",
    "        ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'])\n",
    "    for id, (start, end, proc) in schedule.items():\n",
    "        # cycle through the colors for this processor\n",
    "        color = cycle(colors_by_proc[proc])\n",
    "        colors_by_proc[proc].append(color)\n",
    "        \n",
    "        # handle critical path nodes\n",
    "        if id in critical_path:\n",
    "            critical_kwargs = {\n",
    "                'edgecolor': 'red',\n",
    "                'lw': 2,\n",
    "                'zorder': 100,\n",
    "            }\n",
    "        else:\n",
    "            critical_kwargs = {}\n",
    "        \n",
    "        # blot the bar and text\n",
    "        plt.broken_barh([(start, end-start)],\n",
    "                        (proc-.4, .8),\n",
    "                        facecolors=color,\n",
    "                        **critical_kwargs)\n",
    "        plt.annotate(str(id),\n",
    "                        xy=((start+end)/2, proc),\n",
    "                        ha='center',\n",
    "                        va='center',\n",
    "                        zorder=101)\n",
    "    plt.yticks(list(colors_by_proc.keys()), [f'Proc {proc}' for proc in colors_by_proc.keys()])\n",
    "    plt.tight_layout()\n",
    "\n",
    "print(fn)\n",
    "plot_schedule(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[a,b,c,d,e,g,f,h,i](8 end at 15160)(9 end at 15629)(6 end at 12125)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = fn.parent\n",
    "p.successors()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a,b,c,d,e,g,f,h,i,j](10 end at 18043)(9 end at 15629)(6 end at 12125)\n",
      "         41601 function calls (40451 primitive calls) in 0.040 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     1276    0.013    0.000    0.020    0.000 <ipython-input-29-da47963b1fd8>:85(h)\n",
      "     1245    0.007    0.000    0.028    0.000 <ipython-input-29-da47963b1fd8>:4(__init__)\n",
      "      136    0.005    0.000    0.036    0.000 <ipython-input-29-da47963b1fd8>:49(successors)\n",
      "   1153/3    0.003    0.000    0.039    0.013 <ipython-input-30-bc48c949d841>:26(search)\n",
      "     7231    0.002    0.000    0.002    0.000 <ipython-input-29-da47963b1fd8>:92(<listcomp>)\n",
      "     8108    0.002    0.000    0.002    0.000 {built-in method builtins.all}\n",
      "     4118    0.002    0.000    0.002    0.000 {built-in method builtins.max}\n",
      "     6170    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "     3735    0.001    0.000    0.001    0.000 {method 'copy' of 'dict' objects}\n",
      "     1213    0.001    0.000    0.001    0.000 <ipython-input-29-da47963b1fd8>:97(<listcomp>)\n",
      "      146    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}\n",
      "     1827    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      877    0.000    0.000    0.000    0.000 <ipython-input-29-da47963b1fd8>:61(<listcomp>)\n",
      "     1245    0.000    0.000    0.000    0.000 <ipython-input-29-da47963b1fd8>:75(<lambda>)\n",
      "     1406    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "     1140    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "      415    0.000    0.000    0.000    0.000 <ipython-input-29-da47963b1fd8>:65(<listcomp>)\n",
      "      127    0.000    0.000    0.000    0.000 <ipython-input-29-da47963b1fd8>:45(is_goal)\n",
      "        1    0.000    0.000    0.040    0.040 <ipython-input-30-bc48c949d841>:15(find_best_path)\n",
      "       30    0.000    0.000    0.000    0.000 <ipython-input-30-bc48c949d841>:50(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\cProfile.py:117(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x19a81ca1f40>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "root = Node()\n",
    "ida_star = IDA_star(root = root, graph=graph)\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    final_node = ida_star.find_best_path()\n",
    "\n",
    "print(final_node)\n",
    "stats = pstats.Stats(pr)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(filename='profiling.prof')\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e016cbfee4a4a9f8ad68d1216e5f03d3845a8636147ff93c078e6684dcfe1d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
