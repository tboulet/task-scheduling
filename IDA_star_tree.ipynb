{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/smallRandom.json\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import bisect\n",
    "\n",
    "from config import filename, n_cores\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def n2letter(n):\n",
    "    '''0 to 'a', 1 to 'b', ... '''\n",
    "    return chr(96+n)\n",
    "\n",
    "def string2duration(string):\n",
    "    ''' \"01:50:19.3177493\" to duration in seconds'''\n",
    "    return 3600*int(string[:2]) + 60*int(string[3:5]) + int(string[6:8])  #Duration is int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Number of tasks: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'Data': 2843, 'Dependencies': []},\n",
       " 2: {'Data': 3656, 'Dependencies': [1]},\n",
       " 3: {'Data': 2741, 'Dependencies': [1]},\n",
       " 4: {'Data': 4166, 'Dependencies': [1]},\n",
       " 5: {'Data': 5065, 'Dependencies': [2]},\n",
       " 6: {'Data': 5116, 'Dependencies': [4]},\n",
       " 7: {'Data': 3878, 'Dependencies': [2]},\n",
       " 8: {'Data': 3596, 'Dependencies': [5]},\n",
       " 9: {'Data': 5252, 'Dependencies': [7]},\n",
       " 10: {'Data': 2883, 'Dependencies': [8]}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(path):\n",
    "    global task_count\n",
    "    global tasks\n",
    "    file = open(path)\n",
    "    data = json.load(file)\n",
    "    nodes = data['nodes']\n",
    "    tasks = dict()\n",
    "    for task_str, info in nodes.items():\n",
    "        task = int(task_str)\n",
    "        tasks[task] = {'Data' : string2duration(info['Data']), 'Dependencies' : info['Dependencies']}\n",
    "    task_count = len(tasks)\n",
    "    print(\"Data loaded successfully. Number of tasks: \" + str(task_count))\n",
    "\n",
    "read_data(filename)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [2, 3, 4], 2: [5, 7], 3: [], 4: [6], 5: [8], 6: [], 7: [9], 8: [10], 9: [], 10: []}\n",
      "{1: [], 2: [1], 3: [1], 4: [1], 5: [2], 6: [4], 7: [2], 8: [5], 9: [7], 10: [8]}\n"
     ]
    }
   ],
   "source": [
    "#Tasks to child tasks / Tasks to parents / Task is terminal / Task is inital\n",
    "task2childs = {task : list() for task in tasks}\n",
    "task2parents = {task : list() for task in tasks}\n",
    "for task, info in tasks.items():\n",
    "    #Add childs\n",
    "    list_task_parents = info['Dependencies']\n",
    "    for task_parent in list_task_parents:\n",
    "        task2childs[task_parent].append(task)\n",
    "    #Add parents\n",
    "    task2parents[task] = tasks[task]['Dependencies']\n",
    "    \n",
    "def task_is_terminal(task: int):\n",
    "    return len(task2childs[task]) == 0\n",
    "def task_is_inital(task: int):\n",
    "    return len(task2parents[task]) == 0\n",
    "\n",
    "print(task2childs)\n",
    "print(task2parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 2883,\n",
       " 8: 6479,\n",
       " 5: 11544,\n",
       " 9: 5252,\n",
       " 7: 9130,\n",
       " 2: 15200,\n",
       " 3: 2741,\n",
       " 6: 5116,\n",
       " 4: 9282,\n",
       " 1: 18043}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2sbl = {}\n",
    "\n",
    "def save_static_bottom_level(task : int):\n",
    "    task_duration = tasks[task][\"Data\"]\n",
    "    if task_is_terminal(task):\n",
    "        sbl = task_duration\n",
    "    else:\n",
    "        list_sbl_child = list()\n",
    "        for task_child in task2childs[task]:\n",
    "            if task_child in task2sbl:\n",
    "                sbl_child = task2sbl[task_child]\n",
    "            else:\n",
    "                sbl_child = save_static_bottom_level(task_child)\n",
    "            list_sbl_child.append(sbl_child)\n",
    "        sbl = max(list_sbl_child) + task_duration\n",
    "                \n",
    "    task2sbl[task] = sbl\n",
    "    return sbl\n",
    "\n",
    "for task in tasks:\n",
    "    if task_is_inital(task):\n",
    "        save_static_bottom_level(task)\n",
    "        \n",
    "task2sbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tasks = tasks\n",
    "        self.tasks_to_sbl = task2sbl\n",
    "        self.tasks_to_parent = task2parents\n",
    "        self.tasks_to_child = task2childs\n",
    "        self.n_cores = 2\n",
    "        self.nodes = list()\n",
    "\n",
    "graph = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    graph = graph\n",
    "    \n",
    "    def __init__(self, parent = None, task_to_add = None, core_where_to_add = None, time_task_start = None):\n",
    "        '''Create a Node object ie a partial scheduling\n",
    "        parent = parent Node, None if root\n",
    "        task_to_add : task added to the partial schedule\n",
    "        core_where_to_add : core where to do task\n",
    "        time_task_start : instant where the core will start computing the task\n",
    "        '''        \n",
    "        if parent is None:\n",
    "            self.parent = None\n",
    "            self.tasks_done_time = dict()\n",
    "            self.cores = {core_n : {\"task\" : -1, \"task_end_time\" : 0} for core_n in range(n_cores)}\n",
    "            \n",
    "            self.g = 0\n",
    "            self.f = self.h()\n",
    "                   \n",
    "            self.hist = ''  \n",
    "            self.schedule = dict()\n",
    "            \n",
    "        else:\n",
    "            task_end_time = time_task_start + self.graph.tasks[task_to_add]['Data']\n",
    "            \n",
    "            self.parent = parent\n",
    "            self.tasks_done_time = parent.tasks_done_time.copy()\n",
    "            self.tasks_done_time[task_to_add] = task_end_time\n",
    "\n",
    "            self.cores = parent.cores.copy()\n",
    "            self.cores[core_where_to_add] = {\"task\" : task_to_add, \"task_end_time\" : task_end_time}\n",
    "                \n",
    "            self.g = max(parent.g, task_end_time)\n",
    "            # self.f = max(self.g + self.h(), parent.f)\n",
    "            self.f = self.g + self.h()\n",
    "            \n",
    "            self.schedule = parent.schedule.copy()\n",
    "            self.schedule[task_to_add] = (time_task_start, task_end_time, core_where_to_add)\n",
    "            self.hist = parent.hist + f\"|Task {task_to_add} start at time {time_task_start} on core {core_where_to_add} \"\n",
    "                 \n",
    "    def __repr__(self):\n",
    "        string = '[' + ','.join([n2letter(task) for task in self.tasks_done_time]) + ']'\n",
    "        string += ''.join([f\"({core['task']} end at {core['task_end_time']})\" for core in self.cores.values()])\n",
    "        return string\n",
    "            \n",
    "    def is_goal(self):\n",
    "        '''Return whether a node is a full schedule'''\n",
    "        return len(self.tasks_done_time) == task_count\n",
    "    \n",
    "    def successors(self):                     \n",
    "        '''Create and return list of child node of self'''\n",
    "        childs = list()\n",
    "        \n",
    "        #On regarde toutes les tâches qu'on va tenter de rajouter\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            \n",
    "            #On passe les taches déjà ajoutées\n",
    "            if task in self.tasks_done_time: \n",
    "                continue\n",
    "            \n",
    "            #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]): \n",
    "                continue\n",
    "            \n",
    "            #On calcul le temps ou toutes les dépendances de task seront terminés par les coeurs   \n",
    "            time_all_tasks_done = max([0] + [self.tasks_done_time[task_required] for task_required in info['Dependencies']])\n",
    "                                         \n",
    "            for core_n, core in self.cores.items():\n",
    "                #On ne commence à faire la task que lorsque toutes les dépendances sont calculées et que le core est disponible.\n",
    "                time_core_available = core[\"task_end_time\"]\n",
    "                time_task_start = max(time_all_tasks_done, time_core_available)\n",
    "                \n",
    "                child = Node(parent = self, task_to_add=task, core_where_to_add=core_n, time_task_start=time_task_start)    \n",
    "                childs.append(child)\n",
    "                \n",
    "        return sorted(childs, key = lambda node: node.f)\n",
    "        \n",
    "    def cost(self, child_node):\n",
    "        '''Return the cost of going from self to child_node, a child node of self\n",
    "        '''\n",
    "        res = child_node.g - self.g\n",
    "        if res < 0:\n",
    "            raise Exception(\"Cost difference is negative\")\n",
    "        return res\n",
    "    \n",
    "    def h(self):\n",
    "        '''Estimated remaining time of the node-schedule for reaching a terminal node. Must understimate true value.\n",
    "        '''\n",
    "        successor_tasks = list()\n",
    "        for task, info in self.graph.tasks.items():\n",
    "            if task in self.tasks_done_time: #On passe les taches déjà ajoutées\n",
    "                continue\n",
    "            if not all([task_required in self.tasks_done_time for task_required in info['Dependencies']]):   #On ne garde que les taches dont toutes les dépendances ont été réalisées\n",
    "                continue\n",
    "            successor_tasks.append(task)\n",
    "        if len(successor_tasks) == 0:\n",
    "            return 0\n",
    "        return max([self.graph.tasks_to_sbl[task] for task in successor_tasks])\n",
    "        \n",
    "    \n",
    "    #Node-schedule method\n",
    "    def __lt__(self, node):\n",
    "        return self.f < node.f\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return int(self.f)\n",
    "        \n",
    "    def __eq__(self, node):\n",
    "        '''Return whether a node is equal to another. Two nodes are considered equal if they have completed the same tasks and if all their cores stop working at same time.\n",
    "        '''\n",
    "        if self.g != node.g:\n",
    "            return False       \n",
    "        if self.tasks_done_time != node.tasks_done_time:\n",
    "            return False\n",
    "        return self.set_of_core() == node.set_of_core()\n",
    "        \n",
    "    def set_of_core(self):\n",
    "        return {(core[\"task_end_time\"],) for core_n, core in self.cores.items()}\n",
    "    \n",
    "    def compute_g(self):\n",
    "        return max([core[\"task_end_time\"] for core in self.cores.values()])\n",
    "    \n",
    "# r = Node()\n",
    "# x,y = r.successors()\n",
    "# a,b,c,d,e,f, *_ = x.successors()\n",
    "# g, h, i, j, k, l, *_ = y.successors()\n",
    "\n",
    "# #Test successors\n",
    "# print(a, b, c, d, e, f, sep = '\\n')\n",
    "# print()\n",
    "# print(g, h, i, j, k, l, sep = '\\n')\n",
    "# print()\n",
    "\n",
    "# #Test __eq__\n",
    "# for i in (g, h, i, j, k, l):\n",
    "#     for j in (a, b, c, d, e, f):\n",
    "#         if i == j:\n",
    "#             print(i, j)\n",
    "\n",
    "# #Test cost\n",
    "# x.cost(a)\n",
    "\n",
    "#Test h\n",
    "# print(r.h())\n",
    "# print(x.h())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import queue\n",
    "import random as rd\n",
    "import sys\n",
    "\n",
    "def rdraise(x = 0.1):\n",
    "    if rd.random() < x:\n",
    "        raise\n",
    "\n",
    "class IDA_star():\n",
    "    def __init__(self, root, graph):\n",
    "        self.root = root\n",
    "        self.graph = graph\n",
    "\n",
    "    def find_best_path(self):\n",
    "        self.solution_found = False\n",
    "        bound = self.root.h()\n",
    "        self.path = [self.root]\n",
    "        while len(self.path) > 0:\n",
    "            found, score = self.search(bound)\n",
    "            if found:\n",
    "                return self.path[-1]\n",
    "            bound = score\n",
    "        raise Exception(\"No path from root to a terminal node\")\n",
    "            \n",
    "    def search(self, bound):\n",
    "        '''Search for the fastest way to a terminal node starting to the last node in the path (ie current node)\n",
    "        bound : f-score maximal for keep searching in a branch. If the f-score of a node is inferior to bound, it means bound < f < f_real so the node is the solution.\n",
    "        return : a tuple (FOUND, F_SCORE)\n",
    "            FOUND : whether we have found the terminal node which is the solution\n",
    "            F_SCORE : the true F_SCORE\n",
    "        '''\n",
    "        #Select current node\n",
    "        node = self.path[-1]\n",
    "        #If the f score exceeds the threshold, we cut down the exploration branch by returning this bad f score.\n",
    "        if node.f > bound:         \n",
    "            return False, node.f\n",
    "        #If we reach the goal, it means f_score <= f_score_any_brothers (because node.successors() is sorted) and f_score <= f_score_any_nodes (by construction) so it is the solution\n",
    "        if node.is_goal():\n",
    "            return True, node.f\n",
    "        #We explore the successors of node in order to return the best node\n",
    "        mini = float('inf')    \n",
    "        successors = node.successors()\n",
    "        for succ in successors:\n",
    "            self.path.append(succ)\n",
    "            found, score = self.search(bound)\n",
    "            #We found the solution so we just return True recursively. The solution is the self.path\n",
    "            if found:\n",
    "                #A terminal node was found but we take its best brother in terms of f score\n",
    "                best_node = sorted(self.path[-2].successors(), key = lambda node : node.g + node.h())[0]\n",
    "                self.path[-1] = best_node\n",
    "                return True, score\n",
    "            if score < mini:\n",
    "                mini = score\n",
    "            self.path.pop()\n",
    "        return False, mini\n",
    "            \n",
    "    \n",
    "fn = IDA_star(root = Node(), graph=graph).find_best_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a,b,d,e,g,h,i,f,j,c](6 end at 20276)(3 end at 21763)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import cycle\n",
    "from typing import Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def cycle(lst: list[str]) -> str:\n",
    "    x = lst.pop(0)\n",
    "    lst.append(x)\n",
    "    return x\n",
    "\n",
    "def plot_schedule(node, critical_path=[]) -> None:\n",
    "    schedule = node.schedule\n",
    "    colors_by_proc = defaultdict(lambda:\n",
    "        ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'])\n",
    "    for id, (start, end, proc) in schedule.items():\n",
    "        # cycle through the colors for this processor\n",
    "        color = cycle(colors_by_proc[proc])\n",
    "        colors_by_proc[proc].append(color)\n",
    "        \n",
    "        # handle critical path nodes\n",
    "        if id in critical_path:\n",
    "            critical_kwargs = {\n",
    "                'edgecolor': 'red',\n",
    "                'lw': 2,\n",
    "                'zorder': 100,\n",
    "            }\n",
    "        else:\n",
    "            critical_kwargs = {}\n",
    "        \n",
    "        # blot the bar and text\n",
    "        plt.broken_barh([(start, end-start)],\n",
    "                        (proc-.4, .8),\n",
    "                        facecolors=color,\n",
    "                        **critical_kwargs)\n",
    "        plt.annotate(str(id),\n",
    "                        xy=((start+end)/2, proc),\n",
    "                        ha='center',\n",
    "                        va='center',\n",
    "                        zorder=101)\n",
    "    plt.yticks(list(colors_by_proc.keys()), [f'Proc {proc}' for proc in colors_by_proc.keys()])\n",
    "    plt.tight_layout()\n",
    "\n",
    "print(fn)\n",
    "plot_schedule(fn)\n",
    "plt.savefig('./data/schedule')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[a,b,d,e,g,h,i,f,j](6 end at 20276)(10 end at 19022)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = fn.parent\n",
    "p.successors()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a,b,d,e,g,h,i,f,j,c](6 end at 20276)(3 end at 21763)\n",
      "         7658664 function calls (7385507 primitive calls) in 3.684 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   273243    0.986    0.000    1.485    0.000 <ipython-input-53-575fe90fec89>:85(h)\n",
      "   273222    0.695    0.000    2.348    0.000 <ipython-input-53-575fe90fec89>:4(__init__)\n",
      "    46737    0.588    0.000    3.240    0.000 <ipython-input-53-575fe90fec89>:49(successors)\n",
      "273185/28    0.375    0.000    3.684    0.132 <ipython-input-54-bc48c949d841>:26(search)\n",
      "   956256    0.182    0.000    0.182    0.000 {built-in method builtins.max}\n",
      "   821424    0.144    0.000    0.144    0.000 <ipython-input-53-575fe90fec89>:92(<listcomp>)\n",
      "  1002991    0.125    0.000    0.125    0.000 {built-in method builtins.all}\n",
      "   819666    0.121    0.000    0.121    0.000 {method 'copy' of 'dict' objects}\n",
      "  1184104    0.107    0.000    0.107    0.000 {method 'append' of 'list' objects}\n",
      "   273201    0.087    0.000    0.087    0.000 <ipython-input-53-575fe90fec89>:97(<listcomp>)\n",
      "    46747    0.063    0.000    0.093    0.000 {built-in method builtins.sorted}\n",
      "   456591    0.048    0.000    0.048    0.000 {method 'items' of 'dict' objects}\n",
      "   181567    0.035    0.000    0.035    0.000 <ipython-input-53-575fe90fec89>:61(<listcomp>)\n",
      "   319999    0.032    0.000    0.032    0.000 {built-in method builtins.len}\n",
      "   273222    0.030    0.000    0.030    0.000 <ipython-input-53-575fe90fec89>:75(<lambda>)\n",
      "   136611    0.028    0.000    0.028    0.000 <ipython-input-53-575fe90fec89>:65(<listcomp>)\n",
      "   273147    0.025    0.000    0.025    0.000 {method 'pop' of 'list' objects}\n",
      "    46728    0.015    0.000    0.021    0.000 <ipython-input-53-575fe90fec89>:45(is_goal)\n",
      "        1    0.000    0.000    3.684    3.684 <ipython-input-54-bc48c949d841>:15(find_best_path)\n",
      "       20    0.000    0.000    0.000    0.000 <ipython-input-54-bc48c949d841>:50(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\timot\\AppData\\Local\\Programs\\Python\\Python39\\lib\\cProfile.py:117(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x20ff95f99d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "root = Node()\n",
    "ida_star = IDA_star(root = root, graph=graph)\n",
    "\n",
    "with cProfile.Profile() as pr:\n",
    "    final_node = ida_star.find_best_path()\n",
    "\n",
    "print(final_node)\n",
    "stats = pstats.Stats(pr)\n",
    "stats.sort_stats(pstats.SortKey.TIME)\n",
    "stats.dump_stats(filename='profiling.prof')\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e016cbfee4a4a9f8ad68d1216e5f03d3845a8636147ff93c078e6684dcfe1d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
